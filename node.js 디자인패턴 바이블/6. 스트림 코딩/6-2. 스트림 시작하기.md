# 스트림 해부

- 노드의 스트림은 코어 모듈에서 사용 가능한 4개의 기본 추상 클래스 중 하나의 구현임
  - 기본 추상 클래스 종류 : Readable, Writable, Duplex, Transform
- 스트림은 EventEmitter의 인스턴스임
  - end : 읽기 가능한 스트림이 읽기를 마쳤을 떄 발생
  - finish : 쓰기 스트림이 완료됬을때 발생
  - error : 무언가 잘못됬을때
- 스트림이 매우 유연한 이유중 하나는 바이너리뿐만 아니라 거의 모든 자스의 값을 처리할 수 있음
  - Binary 모드 : 버퍼 또는 문자열과 같은 청크 형태로 데이터 스트리밍
  - 객체 모드 : 데이터를 일련의 개별 객체로 스트리밍(거의 모든 자스의 값 처리 가능)

<br>

# Readable 스트림

- Readable 스트림에는 2개의 데이터 수신 방법이 존재함

### non-flowing 모드

- Readable 스트림에서 읽기를 위한 기본 패턴
- readable 이벤트에 대해서 리스너를 연결하는 작업이 포함됨
- 보통 네트워크 프로토콜을 구현하거나 특정 데이터 형식의 구문을 분석할 때 유용함

```ts
process.stdin
  .on("readable", () => {
    let chunk: Buffer;

    console.log("New data is available");

    /**
     * read는 스트림 내부 버퍼에서 데이터 청크를 가져오는 동기 작업
     * 데이터 형식은 기본적으로 Buffer 타입
     * 더 이상 읽을수있는 값이 없다면 null을 반환함
     */
    while ((chunk = process.stdin.read()) !== null) {
      console.log(`Chunk read: (${chunk.length}), (${chunk.toString()})`);
    }
  })
  .on("end", () => {
    console.log("End of stream");
  });

/**
 * New data is available
 * Chunk read: (12), (hello asdasd)
 * New data is available
 * End of stream
 */
```

<br/>

### flowing 모드

- 데이터 이벤트에 리스너를 연결하면 스트림이 flowing 모드를 사용하도록 전환함
- read()를 사용해서 가져오는게 아닌 도착하자마다 데이터 리스너로 바로 전달됨
- non-flowing 모드보다 데이터 흐름을 제어하는 유연성이 떨어짐
- 스트림이 데이터 이벤트를 보내는것을 일시적으로 중단할려면 pause() 함수를 사용해서 버퍼에 캐싱이 가능함

```ts
process.stdin
  .on("data", (chunk) => {
    console.log("New data is available");
    console.log(`Chunk read: (${chunk.length}), (${chunk.toString()})`);
  })
  .on("end", () => {
    console.log("End of stream");
  });

/**
 * New data is available
 * Chunk read: (12), (hello asdasd)
 * End of stream
 */
```

<br>

### 비동기 iterator

- Readable 스트림은 비동기 iterator 이기도함
- 전체 Readable 스트림을 소비하고 프로미스를 반환하는 함수가 필요할때 해당 패턴이 매우 유용함

```ts
async function main() {
  for await (const chunk of process.stdin) {
    console.log(
      `New data is available: (${chunk.length}), (${chunk.toString()})`
    );
  }

  console.log("End of stream");
}

main();

/**
 * New data is available: (12), (hello asdasd)
 * End of stream
 */
```

<br/>

### Readable 스트림 구현

- Readable 클래스는 내부적으로 `_read` 메소드를 호출함, 해당 함수는 push를 통해서 내부 버퍼를 채움
- read 함수는 사용자가 호출하는 메소드고, \_read는 내부적으로 호출하는것이니 혼동되면 안됨

```ts
import Chance from "chance";
import { Readable } from "stream";

const chance = new Chance();

class RandomStrean extends Readable {
  private emittedBytes: number;

  constructor(options: any) {
    super(options);
    this.emittedBytes = 0;
  }

  _read(size: number) {
    const chunk = chance.string({ length: size });
    this.push(chunk, "utf-8");
    this.emittedBytes += chunk.length;
    if (chance.bool({ likelihood: 5 })) {
      this.push(null);
    }
  }
}

const randomStream = new RandomStrean({});
randomStream
  .on("data", (chunk) => {
    console.log(chunk.toString());
  })
  .on("end", () => {
    console.log("End of stream");
  });
```

<br/>

### 단순화된 생성자

- 단순화된 생성자 접근방식을 사용해서 사용자 정의 클래스 생성을 피할 수 있음

```ts
import Chance from "chance";
import { Readable } from "stream";

const chance = new Chance();

let emittedBytes = 0;

const randomStream = new Readable({
  read(size) {
    const chunk = chance.string({ length: size });
    this.push(chunk, "utf-8");
    emittedBytes += chunk.length;
    if (chance.bool({ likelihood: 5 })) {
      this.push(null);
    }
  },
});

console.log(randomStream.read(10));
```

<br/>

### iterator에서 Readable 스트림 얻기

- `Readable.from를 사용해서 iterable 객체에서 Readable 스트림의 인스턴스를 쉽게 만들수있음

```ts
import { Readable } from "stream";

const mountains = [
  { name: "Everest", height: 8848 },
  { name: "K2", height: 8611 },
  { name: "Kangchenjunga", height: 8586 },
  { name: "Lhotse", height: 8516 },
  { name: "Makalu", height: 8485 },
];

const mountainsStream = Readable.from(mountains);
mountainsStream.on("data", (chunk) => {
  console.log(`${chunk.name.padStart(14)} ${chunk.height}m`);
});
```

<br/>

# Writable 스트림

- 대상의 목적지를 나타내는 스트림

<br/>

### 스트림에 쓰기

- write() 함수를 통해 일부 데이터를 Writable 스트림에 쓸 수 있음
- end() 함수를 통해서 더이상 기록할 데이터가 없다는걸 알려줌
  - 또한 최종 데이터 청크를 제공할 수 있음

```ts
import { Chance } from "chance";
import { createServer } from "http";

const chance = new Chance();

const server = createServer((req, res) => {
  res.writeHead(200, { "Content-Type": "text/plain" });

  // 5% 확률로 종료되는 루프
  while (chance.bool({ likelihood: 99 })) {
    res.write(`${chance.string()}\n`);
  }
  res.end("\n\n");
  res.on("finish", () => {
    console.log("All data was sent");
  });
});

server.listen(8080, () => {
  console.log("Server is running on http://localhost:8080");
});
```

<br/>

### Backpressure

- 노드의 스트림은 소비할수있는 것보다 더 빨리 데이터가 기록되는 병목현상을 겪을수 있음
  - 이러한 문제는 들어오는 데이터를 버퍼링해서 대처가 가능함
  - 하지만 스트림이 데이터 생성자에게 피드백을 주지 않는다면 계속해서 버퍼가 쌓여서 메모리 문제가 발생할 수 있음
- 배압 매커니즘은 내부 크기의 버퍼를 제한하는 매커니즘으로 버퍼가 비워지면 다시 쓰기를 시작해도 안전함을 나타냄
  - 배압 매커니즘은 원하지 않는 메모리 사용을 방지하는 권고 매커니즘임

```ts
import { Chance } from "chance";
import { createServer } from "http";

const chance = new Chance();

const server = createServer((req, res) => {
  res.writeHead(200, { "Content-Type": "text/plain" });

  function generateMore() {
    while (chance.bool({ likelihood: 95 })) {
      const randomChunk = chance.string({
        length: 16 * 1024 - 1,
      });
      const shouldContinue = res.write(randomChunk);
      if (!shouldContinue) {
        console.log("Backpressure");
        return res.once("drain", generateMore);
      }
    }
  }

  generateMore();
  res.on("finish", () => {
    console.log("All data was sent");
  });
});

server.listen(8080, () => {
  console.log("Server is running on http://localhost:8080");
});
```

<br/>

### Writable 스트림 구현

- Wrtiable 클래스를 상속하고 \_write() 함수에 대한 구현을 제공해서 새로운 Writeable 구현이 가능함
- 아래 예제는 커스텀 Writable 스트림에 2개의 파일이 생성되고 저장됨

```ts
import { Writable } from "stream";
import * as mkdirp from "mkdirp";
import { promises as fs } from "fs";
import path, { dirname } from "path";

class ToFileStream extends Writable {
  constructor(options: any) {
    super({ ...options, objectMode: true });
  }

  _write(
    chunk: any,
    encoding: BufferEncoding,
    callback: (error?: Error | null) => void
  ): void {
    mkdirp
      .mkdirp(dirname(chunk.path))
      .then(() => fs.writeFile(chunk.path, chunk.content))
      .then(() => callback())
      .catch(callback);
  }
}

const tfs = new ToFileStream({});

tfs.write({
  path: "static/fileA.txt",
  content: "Hello World",
});

tfs.write({
  path: "static/fileB.txt",
  content: "Hello World 2",
});

tfs.end(() => {
  console.log("done");
});
```

<br/>

### 단순화된 생성자

```ts
import { Writable } from "stream";
import * as mkdirp from "mkdirp";
import { dirname } from "path";
import { promises as fs } from "fs";

const tfs = new Writable({
  objectMode: true,
  write(chunk, encoding, callback) {
    console.log(chunk);

    mkdirp
      .mkdirp(dirname(chunk.name))
      .then(() => {
        fs.writeFile(chunk.name, chunk.content);
      })
      .catch(callback);
  },
});

tfs.write({ name: "static/filev.txt", content: "Hello World" }, "utf8", () => {
  console.log("done");
});
```

<br/>

# Duplex 스트림

- 읽기 및 쓰기가 동시에 가능한 스트림
- 네트워크 소켓같이 데이터 소스이자 데이터 목적지인 엔티티를 설명하려는 경우 유용함
- \_read(), \_write() 메소드를 모두 구현해야함

<br/>

# Transform 스트림

- 데이터 변환을 처리하도록 특별히 설계된 특수한 종류의 Duplex 스트림
- 데이터 사이의 관계가 없음
- \_read(), \_write() 처럼 \_transform(), \_flush() 메소드를 구현해야함

<br/>

### Transform 스트림 구현

```ts
import { Transform, TransformCallback } from "stream";

class ReplaceStream extends Transform {
  private searchString: string;
  private replaceString: string;
  private tail: string;

  constructor(searchString: string, replaceString: string, options: any) {
    super(options);
    this.searchString = searchString;
    this.replaceString = replaceString;
    this.tail = "";
  }

  _transform(
    chunk: any,
    encoding: BufferEncoding,
    callback: TransformCallback
  ): void {
    const pieces = (this.tail + chunk).split(this.searchString);
    const lastPiece = pieces[pieces.length - 1];
    const tailLen = this.searchString.length - 1;
    this.tail = lastPiece.slice(-tailLen);
    pieces[pieces.length - 1] = lastPiece.slice(0, -tailLen);

    // 내부 읽기 버퍼로 데이터 저장
    this.push(pieces.join(this.replaceString));
    callback();
  }

  /**
   * 스트림이 종료되기전에 호출되고 남은 데이터를 저장함
   * @param callback
   */
  _flush(callback: TransformCallback): void {
    this.push(this.tail);
    callback();
  }
}

const replaceStream = new ReplaceStream("world", "node.js", {});

replaceStream.on("data", (chunk) => {
  console.log(chunk.toString());
});

replaceStream.write("hello world");
replaceStream.write("world");
replaceStream.end();
```

<br/>

### 단순화된 생성자

```ts
import { Transform } from "stream";

const searchStr = "World";
const replaceStr = "Node.js";
let tail = "";

const replaceStream = new Transform({
  defaultEncoding: "utf-8",
  transform(chunk, encoding, callback) {
    let pieces = (tail + chunk).split(searchStr);
    const lastPiece = pieces[pieces.length - 1];
    const tailLen = searchStr.length - 1;
    tail = lastPiece.slice(-tailLen);
    pieces[pieces.length - 1] = lastPiece.slice(0, -tailLen);
    this.push(pieces.join(replaceStr));
    callback();
  },
  flush(callback) {
    this.push(tail);
    callback();
  },
});
```

<br/>

### Transform 스트림을 사용한 데이터 필터링 및 집계

- Transform 스트림은 데이터 변환 파이프라인을 구현하기 위한 완벽한 블록임
- 또한 다른 유형의 데이터 변환을 구현도 가능함
- 아래 예시는 이전 연도의 매출을 포함하는 큰 파일을 분석하는 예시임

```ts
import { Parser } from "csv-parse";
import { createReadStream } from "fs";
import { Transform, TransformCallback } from "stream";

/**
 * country 필드를 기준으로 데이터를 필터링하는 Transform 스트림
 */
class FilterByCountry extends Transform {
  private country: string;

  constructor(country: string, options: any) {
    super(options);
    this.country = country;
  }

  _transform(
    chunk: any,
    encoding: BufferEncoding,
    callback: TransformCallback
  ): void {
    if (chunk.country === this.country) {
      this.push(chunk);
    }
    callback();
  }
}

/**
 * 금액의 합계를 처리하는 Transform 스트림
 */
class SumProfit extends Transform {
  private total: number;

  constructor(options: any) {
    super(options);
    this.total = 0;
  }

  _transform(
    chunk: any,
    encoding: BufferEncoding,
    callback: TransformCallback
  ): void {
    this.total += Number.parseFloat(chunk.profit);
    callback();
  }

  _flush(callback: TransformCallback): void {
    this.push(this.total.toString());
    callback();
  }
}

const csvParser = new Parser({ columns: true });

createReadStream("static/transform.csv")
  .pipe(csvParser)
  .pipe(new FilterByCountry("italy", { objectMode: true }))
  .pipe(new SumProfit({ objectMode: true }))
  .pipe(process.stdout);
```

<br/>

# PassThrough 스트림

- 변환을 적용하지 않고 모든 데이터 청크를 출력하는 특수한 유형의 변환
- 관찰이 가능하고 느린 파이프 연결과 지연 스트림을 구현하는데 유용함

<br/>

### 관찰 가능성(Observability)

- 흐르는 데이터의 양을 관찰할려면 데이터 이벤트 리스너를 PassThroutght 인스턴스에 연결함
- 원하는 지정된 지점에서 해당 인스턴스를 파이프라인으로 연결해서 수행이 가능함

```ts
import { PassThrough } from "stream";

let bytesWritten = 0;

const monitor = new PassThrough();
monitor.on("data", (chunk) => {
  bytesWritten += chunk.length;
});

monitor.on("finish", () => {
  console.log(`${bytesWritten} bytes written`);
});

monitor.write("hello");
monitor.write("world");
monitor.end(); // 10 bytes written

createReadStream("static/transform.csv")
  .pipe(createGzip())
  .pipe(monitor)
  .pipe(createWriteStream("static/transform.csv.gz")); // 139 bytes written
```

<br/>

### 느린 파이프 연결(Late piping)

- 스트림을 파라미터로 받아서 처리해야되는 경우가 종종 생김
- 하지만 주어진 API를 호출하고나서 스트림을 통해 I/O를 할려는 경우 더 복잡할수도 있음

```ts
import { createReadStream } from "fs";
import { basename } from "path";
import { PassThrough } from "stream";
import { createBrotliCompress } from "zlib";

export async function upload(filename: string, contentStream: any) {
  console.log(`Uploading ${filename}...`);

  return {
    data: "",
  };
}

const filepath = process.argv[2];
const filename = basename(filepath);
const contentStream = new PassThrough();

upload(`${filename}.br`, contentStream)
  .then((response) => console.log(response))
  .catch((err) => console.log(err));

createReadStream(filepath).pipe(createBrotliCompress()).pipe(contentStream);
```

<br/>

# 지연(Lazy) 스트림

- 동시에 다수의 스트림을 생성해야되는 경우가 존재함
- 하지만 순간적으로 많은 스트림을 생성하게 되면 EMFILE 이라는 너무 많은 파일이 열렸다는 오류가 발생할수도 있음
  - 실제로 fs.createReadStream 같은 함수가 해당 스트림에서 읽기를 시작하기전에 실제로 파일 디스크립터를 열기때문임
- lazystream 같은 외부 라이브러리를 사용하면 실제 스트림에서 데이터를 소비할때까지 비용이 많이 드는 초기화를 지연시킬수 있음

```ts
import { createReadStream } from "fs";
import lazystream from "lazystream";

const lazyURandom = new lazystream.Readable((options) => {
  return createReadStream("dev/urandom");
});
```

<br/>

# 파이프를 사용해서 스트림 연결하기

- 프로그램의 출력이 다음 프로그램의 입력으로 연결될 수 있음
- pipe() 함수는 Readable 스트림에서 방출된 데이터를 제공된 Writable 스트림으로 전달함
- 이처럼 2개의 스트림을 파이프로 연결하면 흡입이 생성되서 read, write를 수동으로 호출할 필요가 없어짐

<br/>

### 파이프 및 오류처리

- pipe를 사용할 때 오류 이벤트는 파이프라인을 통해서 자동으로 전파되지 않음
- 매번 스트림마다 에러 핸들링을 따로 해줘야함
- 또한 실패한 스트림을 릴리즈하지 않는경우 메모리 누수로 이어질수도 있음

```ts
stream1
  .pipe(stream2)
  .on("error", (err) => {
    console.log(err);
  })
  .pipe(stream3)
  .on("error", (err) => {
    console.log(err);
  });
```

이런 끔찍한 모양이 나옴

<br/>

### pipeline()을 사용한 개선된 오류처리

- 수동으로 에러를 처리하는건 번거롭고 에러가 발생할 확률이 높음, 꼭 피해야함
- 다행히 코어 스트림 패키지는 파이프라인 구축을 위한 `pipeline()` 함수를 제공해줌

```ts
import { pipeline, Transform } from "stream";
import { createGunzip, createGzip } from "zlib";

const uppercasify = new Transform({
  transform(chunk, encoding, callback) {
    this.push(chunk.toString().toUpperCase());
    callback();
  },
});

pipeline(
  process.stdin,
  createGunzip(),
  uppercasify,
  createGzip(),
  process.stdout,
  (err) => {
    if (err) {
      console.error(err);
      process.exit(1);
    }
  }
);
```
