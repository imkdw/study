# 복제 및 로드밸런싱

- 기존의 멀티스레드 웹 서버는 사용 가능한 모든 프로세스, 메모리를 사용해서 모든 처리능력 사용이 가능
- 노드의 경우 단일스레드 환경으로 기존 웹 서버에 비해서 더 빠른 확장이 필요함

<br/>

# 클러스터 모듈

- 여러 인스턴스에게 부하를 분산하는 가장 간단한 패턴
- 마스터 프로세스가 요청을 받고, 워커 프로세스에세 작업을 분산
- 보통 라운드로빈 알고리즘으로 분산하여 모든 워커들에게 균등하게 분산됨

<br/>

### 간단한 웹 서버

- 현재는 동일한 CPU가 처리하므로 pid가 동일

```ts
import { createServer } from "http";

const { pid } = process;
const server = createServer((req, res) => {
  let i = 1e7;
  while (i > 0) {
    i--;
  }

  console.log(`Worker pid: ${pid}`);
  res.end(`Hello from worker ${pid}`);
});

server.listen(8080, () => {
  console.log(`Master pid: ${pid}`);
});
```

<br/>

### 클러스터 모듈을 통한 확장

- 기존 단일 프로세스보다 처리가능한 양이 9~10배정도 늘어남

```ts
import { createServer } from "http";
import { cpus } from "os";
import cluster from "cluster";

if (cluster.isMaster) {
  const availableCpus = cpus();
  console.log("Clustering with %d CPUs", availableCpus.length);

  availableCpus.forEach(() => cluster.fork());
} else {
  const { pid } = process;

  const server = createServer((req, res) => {
    let i = 1e7;
    while (i > 0) {
      i--;
    }

    res.end(`Hello from worker ${pid}`);
  });

  server.listen(8080, () => {
    console.log(`Worker pid: ${pid}`);
  });
}
```

<br/>

### 클러스터 모듈의 탄력성 및 가용성

- 워커 프로세스는 모두 별도이므로 다른 작업자에게 사이드이펙트 없이 프로그램에서 제거/추가가 가능함
- 노드는 워커의 수를 자동으로 관리해주지 않고, 자체 요구사항에 따라서 관리하는건 앱의 책임임
- 여러개의 인스턴스가 존재할때는 작업자 중 하나가 실패하더라도 수신 요청을 처리할 수 있는 백업 프로세스가 항상 존재함

```ts
import { createServer } from "http";
import { cpus } from "os";
import cluster from "cluster";

if (cluster.isMaster) {
  const availableCpus = cpus();
  console.log("Clustering with %d CPUs", availableCpus.length);
  availableCpus.forEach(() => cluster.fork());

  cluster.on("exit", (worker, code) => {
    if (code !== 0 && !worker.exitedAfterDisconnect) {
      console.log(`Worker ${worker.id} crashed. Restarting...`);
      cluster.fork();
    }
  });
} else {
  setTimeout(() => {
    throw new Error("OOOPS");
  }, Math.ceil(Math.random() * 3) * 1000);
  const { pid } = process;

  const server = createServer((req, res) => {
    let i = 1e7;
    while (i > 0) {
      i--;
    }

    res.end(`Hello from worker ${pid}`);
  });

  server.listen(8080, () => {
    console.log(`Worker pid: ${pid}`);
  });
}
```

```
Req/Bytes counts sampled once per second.
# of samples: 10

25k requests in 10.04s, 3.48 MB read
1k errors (7 timeouts)
```

워커가 랜덤으로 종료되고 실행되는 도중에도 25000개의 요청중에 1000개만 실패함

<br/>

### 다운타임 제로 시작

- 종종 새로운 버전 릴리즈를 위해서 어플리케이션에 다운타임이 발생할수도 있음
- 다운타임은 새로운 요청 처리가 불가능하며 일부 제약에 따라서 다운타임이 있으면 안됨
- SIGUSR2 신호를 받으면 워커를 종료하고 새로운 워커를 생성하는 방식으로 다운타임 제로 시작 구현이 가능함

```ts
import { createServer } from "http";
import { cpus } from "os";
import cluster from "cluster";
import { once } from "events";

const { pid } = process;

if (cluster.isMaster) {
  console.log("master", pid);

  const availableCpus = cpus();
  console.log("Clustering with %d CPUs", availableCpus.length);
  availableCpus.forEach(() => cluster.fork());

  process.on("SIGUSR2", async () => {
    const workers = Object.values(cluster.workers!);
    for (const worker of workers) {
      console.log("Stopping Worker: %d", worker?.process.pid);
      worker?.disconnect();
      await once(worker!, "exit");
      if (!worker?.exitedAfterDisconnect) {
        continue;
      }
      const newWorker = cluster.fork();
      await once(newWorker!, "listening");
    }
  });
} else {
  const server = createServer((req, res) => {
    let i = 1e7;
    while (i > 0) {
      i--;
    }

    res.end(`Hello from worker ${pid}`);
  });

  server.listen(8080, () => {
    console.log(`Worker pid: ${pid}`);
  });
}
```

<br/>

# 상태 저장 통신 다루기

- 클러스터의 모듈은 각 캐싱된 데이터가 개별 워커에 남아있다는 점이다
- 이는 클러스터에만 국한된 문제는 아니지만 일반적으로 모든 종류의 상태가 저장되지 않는 로드밸런싱 알고리즘에 적용됨

<br/>

### 여러 인스턴스의 상태 공유

- 외부 저장소인 데이터베이스나 redis 같은 캐시계층을 사용할수도 있음
- 단점은 기존 코드에서 바꿔야하는 부분이 상당히 많음
- 간단하게 할려면 스티키 세션처럼 고정 로드 밸런싱을 사용할수도 있음

<br/>

### 고정 로드 밸런싱

- 모든 요청을 항상 고정된 앱 인스턴스로 라우팅하는 방법이 고정 로드 밸런ㅅ싱임
- 로드밸런서가 새로운 요청을 수신하면 로드 밸런싱 알고리즘에 의해서 선택된 인스턴스가 아닌 고정적으로 인스턴스에게 라우팅함
- 보통 세션 아이디나 IP를 기반으로 처리함, 그러나 IP의 경우 LTE 환경이나 네트워크 로밍 등 일부 환경에서는 제대로 작동하지 않음
- 하지만 고정된 인스턴스에서 장애가 발생할경우 답이 없으므로 가능하면 공유 저장소에서 세션 상태를 유지하는게 좋음

<br/>

# 역방향 프록시 확장

- 클러스터 말고도 전통적인 기술들은 고가용성 운영 환경에서 더 많은 제어와 성능을 보장해주므로 선호됨
- 동일한 앱을 실행하는 인스턴스에게 로드밸런서를 통해서 트래픽 분산하는 방식으로 구현함
- Nginx, HAProxy 등 다양한 방법이 있음

<br/>

# 동적 수평 확장

- 미리 서버의 개수를 모르는 상태에서 트래픽을 기반으로 동적으로 서버의 개수를 조정할 수 있음

<br/>

### 서비스 레지스트리 사용

- 일반적인 패턴으로 실행중인 서버와 이들이 제공하는 서비스를 추적하는 중앙서비스(서비스 레지스트리)를 사용하는것임

<br/>

# 피어 투 피어 로드밸런싱

- 기존 중앙집중식 아키텍쳐에서 로드밸런싱을 제거해서 클라이언트 -> 서버로 직접적인 접근을 하는 방식

<br/>

# 컨테이너를 사용한 앱 확장

- Docker를 사용해서 컨테이너를 통한 확장이 가능함

<br/>

### Kubernetes?

- Docker를 관리할 수 있는 도구
