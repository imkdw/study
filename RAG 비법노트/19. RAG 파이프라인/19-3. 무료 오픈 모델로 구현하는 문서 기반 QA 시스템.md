# Ollama로 모델 가져오기
- 한국어 처리를 잘하는 **exaone3.5** 모델 사용
- 임베딩 모델은 bge-m3 사용
```
ollama pull exaone3.5:7.8b
ollama pull bge-m3
```

<br>

# RAG 시스템 구축하기
### 로컬 모델 사용
```python
from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_teddynote import logging

load_dotenv()

logging.langsmith("test")

# ==============================================

from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_teddynote.messages import stream_response

llm = ChatOllama(model="exaone3.5:7.8b", temperature=0)

prompt = ChatPromptTemplate.from_template("{topic}에 대해서 설명해줘")

chain = prompt | llm | StrOutputParser()

answer = chain.stream({"topic": "딥러닝"})

# 딥러닝은 인공지능(AI)의 한 분야로, 인간의 뇌 신경망 구조를 모방하여 설계된 인공 신경망을 사용하는 기계 학습 기법입니다. 주요 특징과 개념은 다음과 같습니다:

# 1. **다층 신경망 구조**: 딥러닝 모델은 여러 층으로 구성된 인공 신경망을 사용합니다. 각 층은 데이터의 복잡한 특징을 추출하고 학습합니다. 예를 들어, 첫 번째 층은 간단한 패턴을 인식하고, 더 깊은 층은 더 복잡한 패턴을 학습합니다.

# 2. **자동 특징 추출**: 전통적인 머신 러닝과 달리, 딥러닝은 수동으로 특징을 설계할 필요가 없습니다. 대신 모델이 데이터로부터 직접 중요한 특징을 자동으로 학습하고 추출합니다. 이는 이미지 인식, 음성 인식 등 다양한 분야에서 매우 효과적입니다.

# 3. **대규모 데이터와 계산력 필요**: 딥러닝 모델은 대량의 데이터와 강력한 컴퓨팅 자원(예: GPU)을 필요로 합니다. 이러한 자원 덕분에 복잡한 패턴을 효과적으로 학습할 수 있습니다.

# 4. **응용 분야**: 딥러닝은 다양한 분야에서 활용됩니다.
#    - **이미지 및 비디오 분석**: 객체 인식, 이미지 분류, 비디오 이해 등
#    - **자연어 처리**: 번역, 텍스트 생성, 감성 분석 등
#    - **음성 인식 및 합성**: 음성 비서, 음성 번역 등
#    - **게임 및 로봇 공학**: 의사결정, 제어 시스템 등

# 5. **주요 알고리즘**:
#    - **컨볼루션 신경망 (CNN)**: 이미지 및 비디오 데이터 처리에 특화
#    - **순환 신경망 (RNN) 및 변형 (LSTM, GRU)**: 시계열 데이터와 순차적 데이터 처리에 효과적
#    - **전결합 신경망 (FNN)**: 일반적인 분류 및 회귀 문제에 사용
#    - **생성 적대 신경망 (GAN)**: 새로운 데이터 생성 (예: 이미지, 음성)

# 딥러닝은 복잡한 문제 해결에 있어 뛰어난 성능을 보여주지만, 모델의 해석성과 데이터 의존성 등 고려해야 할 한계점도 있습니다. 그럼에도 불구하고 지속적인 연구와 발전으로 다양한 산업 분야에서 혁신을 이끌고 있습니다.%  
stream_response(answer)
```

<br>

### 임베딩
```python
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_teddynote.messages import stream_response
from langchain_ollama import OllamaEmbeddings


def similarity(a, b):
    return cosine_similarity([a], [b])[0][0]


llm = ChatOllama(model="exaone3.5:7.8b", temperature=0)

prompt = ChatPromptTemplate.from_template("{topic}에 대해서 설명해줘")

chain = prompt | llm | StrOutputParser()

embeddings = OllamaEmbeddings(model="bge-m3")

sentence1 = "안녕하세요? 반갑습니다."
sentence2 = "안녕하세요? 반갑습니다!"
sentence3 = "안녕하세요? 만나서 반가워요."
sentence4 = "Hi, nice to meet you."
sentence5 = "I like to eat apples."

from sklearn.metrics.pairwise import cosine_similarity

sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]
embedded_sentences = embeddings.embed_documents(sentences)

"""
[유사도 0.9800] 안녕하세요? 반갑습니다.          <=====>         안녕하세요? 반갑습니다!
[유사도 0.9401] 안녕하세요? 반갑습니다.          <=====>         안녕하세요? 만나서 반가워요.
[유사도 0.8568] 안녕하세요? 반갑습니다.          <=====>         Hi, nice to meet you.
[유사도 0.5516] 안녕하세요? 반갑습니다.          <=====>         I like to eat apples.
[유사도 0.9203] 안녕하세요? 반갑습니다!          <=====>         안녕하세요? 만나서 반가워요.
[유사도 0.8385] 안녕하세요? 반갑습니다!          <=====>         Hi, nice to meet you.
[유사도 0.5307] 안녕하세요? 반갑습니다!          <=====>         I like to eat apples.
[유사도 0.9254] 안녕하세요? 만나서 반가워요.     <=====>         Hi, nice to meet you.
[유사도 0.5611] 안녕하세요? 만나서 반가워요.     <=====>         I like to eat apples.
[유사도 0.5955] Hi, nice to meet you.    <=====>         I like to eat apples.
"""
for i, sentence in enumerate(embedded_sentences):
    for j, other_sentence in enumerate(embedded_sentences):
        if i < j:
            print(
                f"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \t <=====> \t {sentences[j]}"
            )
```

<br>

### RAG 체인 구성
- 생략