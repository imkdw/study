# JSON 형식 출력 파서
- `JsonOutputParser`는 LLM이 응답을 단순한 텍스트가 아닌 지정된 스키마에 맞게 JSON 형식으로 변환해줌
- LLM이 데이터를 정확하고 효율적으로 처리하여 유저가 원하는 JSON 형태로 변환하기 위해서는 모델의 용량이 충분히 커야함
- 용량이 작은 모델에서 사용시 오류가 발생할수도 있음

```python
from dotenv import load_dotenv
from langchain_teddynote import logging

load_dotenv()
logging.langsmith("langchain_test")

# ========================================================================

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field

model = ChatOpenAI(temperature=0, model_name="gpt-4.1-mini")


# 데이터 구조 정의
class Topic(BaseModel):
    description: str = Field(description="주제에 대한 간결한 설명")
    hashtags: str = Field(description="해시태그 형식의 키워드(2개 이상)")


question = "메이플스토리 환불사태에 대해서 알려주세요"

parser = JsonOutputParser(pydantic_object=Topic)
print(parser.get_format_instructions())

prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "당신은 친절한 AI 어시스턴트 입니다. 질문에 간결하게 답변하세요."),
        ("user", "#Format: {format_instructions}\n\n#Question: {question}"),
    ]
)

prompt = prompt.partial(format_instructions=parser.get_format_instructions())

chain = prompt | model | parser

answer = chain.invoke({"question": question})

# {
#     "description": "메이플스토리 환불사태는 게임 내 결제한 아이템이나 캐시를 환불 요청하는 이용자들이 급증하면서 발생한 문제로, 회사와 이용자 간의 갈등과 서비스 운영에 대한 논란을 일으킨 사건입니다.",
#     "hashtags": "#메이플스토리 #환불사태 #게임논란 #온라인게임",
# }
print(answer)
```