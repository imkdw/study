# 구조화된 출력 파서
- `StructuredOutputParser`는 LLM에 대한 답변을 딕셔너리 형식으로 정의함
- key, value 쌍으로 여러 필드를 반환하는 데이터 구조화에 유용함
- 상용 모델보다는 로컬 모델에서 더 적합할 수 있음
- 이는 로컬 모델의 경우는 원하는 형식으로 데이터가 나오지 않는 경우가 많기 때문임

```python
from dotenv import load_dotenv
from langchain_teddynote import logging

load_dotenv()
logging.langsmith("langchain_test")

# ========================================================================

from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# 사용자의 질문에 대한 답변
# ResponseSchema를 통해서 질문에 대한 답변과 사용된 소스에 대한 설명을 포함하는 스키마를 정의함
response_schemas = [
    ResponseSchema(name="answer", description="사용자의 질문에 대한 답변"),
    ResponseSchema(
        name="source",
        description="사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.",
    ),
]

# 응답 스키마를 기반으로 구조화된 출력 파서 초기화
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# 출력 형식 지시사항을 파싱
# {
#         "answer": string  // 사용자의 질문에 대한 답변
#         "source": string  // 사용자의 질문에 답하기 위해 사용된 `출처`, `웹사이트주소` 이여야 합니다.
# }
format_instructions = output_parser.get_format_instructions()


prompt = PromptTemplate(
    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정
    template="answer the users question as best as possible.\n{format_instructions}\n{question}",
    input_variables=["question"],
    partial_variables={"format_instructions": format_instructions},
)

model = ChatOpenAI(temperature=0)
chain = prompt | model | output_parser

# {
#     "answer": "메이플스토리는 넥슨사에서 개발한 대규모 다중 사용자 온라인 롤플레잉 게임으로, 플레이어는 가상 세계인 메이플 월드에서 다양한 활동을 할 수 있습니다.",
#     "source": "https://ko.wikipedia.org/wiki/%EB%A9%94%EC%9D%B4%ED%94%8C%EC%8A%A4%ED%86%A0%EB%A6%AC",
# }
print(chain.invoke({"question": "메이플스토리는 어떤 게임인가요?"}))
```