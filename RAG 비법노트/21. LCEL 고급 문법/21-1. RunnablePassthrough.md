# RunnablePassthrough
- 데이터를 받아서 그대로 전달하는 역할을 함
- 그냥 전달만 한다면 왜 필요한가 싶지만 이건 마치 메세지를 전달하는 중간 다리처럼 파이프라인 안에서 자리를 잡아주는 역할을 해줌
- 단순한 입력을 그대로 넘길수도 있지만 추가적인 키를 덧붙여서 함께 전달도 가능함

<br>

### RunnableParallel과 사용
- RunnableParallel은 병렬 처리를 하는데 입력 값을 여러 군데에서 받아서 이것을 적절한 키에 할당해서 전달함
- 이 때 assign() 메소드를 사용하면 전달한 덮어쓰지 않고 새로운 값을 하나 할당해줌
```python
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

runnable = RunnableParallel(
    passed=RunnablePassthrough(),
    # num * 3을 반환하는 람다식 설정
    extra=RunnablePassthrough.assign(mult=lambda x: x["num"] * 3),
    # num + 1을 반환하는 람다식 설정
    modified=lambda x: x["num"] + 1,
)

# {"passed": {"num": 1}, "extra": {"num": 1, "mult": 3}, "modified": 2}
print(runnable.invoke({"num": 1}))
```

<br>

# 리트리버에서 사용하는 방법
```python
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

vectorstore = FAISS.from_texts(
    [
        "테디는 랭체인 주식회사에서 근무를 하였습니다.",
        "셜리는 테디와 같은 회사에서 근무하였습니다.",
        "테디의 직업은 개발자입니다.",
        "셜리의 직업은 디자이너입니다.",
    ],
    embedding=OpenAIEmbeddings(),
)

retriever = vectorstore.as_retriever()

template = """Answer the question based only on the following context:
{context}

Question: {question}
"""

prompt = ChatPromptTemplate.from_template(template)

model = ChatOpenAI(model_name="gpt-4o-mini")


def format_docs(docs):
    return "\n".join([doc.page_content for doc in docs])


retrieval_chain = (
    # context 내부에는 검색 쿼리를 리트리버를 통해서 가져온 항목이 포메팅되서 들어감
    # question은 사용자의 질문이 RunnablePassthrough를 통해서 그대로 전달됨
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

print(retrieval_chain.invoke("테디의 직업은 무엇입니까?"))
```