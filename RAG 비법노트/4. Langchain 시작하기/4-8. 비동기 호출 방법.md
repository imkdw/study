# 동기와 비동기
- 동기 : 작업이 완료될 때 까지 기다림
- 비동기 : 작업이 완료되는 동안 다른거 할 수 있음
- 비동기처리는 사용자 경헝믈 크게 향상시키는 핵심 기술임
- 비동기 처리 덕분에 하나의 요청이 처리되는 동안에도 다른 사용자들의 요청을 동시에 처리할 수 있음
- 비동기 처리가 없다면 한 사용자의 요청이 초리되는 동안 다른 사용자들은 기다려야 하는 심각한 문제가 발생할 수 있음

<br>

# async stream: 비동기 스트림
- `astream()` 함수는 비동기 스트림을 생성해서 특정 주제의 메시지를 비동기적으로 처리함
- for 반복문(async for)을 사용해서 스트림으로부터 메세지를 하나씩 순차적으로 가져옴
```python
from dotenv import load_dotenv
from langchain_teddynote import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import asyncio


load_dotenv()

logging.langsmith("langchain_test")

model = ChatOpenAI(model="gpt-4o-mini")

prompt = PromptTemplate.from_template("{topic}에 대해서 3문장으로 설명해줘")

chain = prompt | model | StrOutputParser()


async def main():
    async for token in chain.astream({"topic": "메이플스토리"}):
        """
        메
        이
        플
        스토
        리는
        넥
        슨
        에서
        개발
        한
        ...
        """
        print(token)


if __name__ == "__main__":
    asyncio.run(main())
```

<br>

# async invoke: 비동기 호출
- `ainvoke()`는 작업을 비동기적으로 처리하는 함수
- 특정 토픽에 대한 처리를 비동기적으로 요청하는데 사용이 가능함

```python
from dotenv import load_dotenv
from langchain_teddynote import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import asyncio


load_dotenv()

logging.langsmith("langchain_test")

model = ChatOpenAI(model="gpt-4o-mini")

prompt = PromptTemplate.from_template("{topic}에 대해서 3문장으로 설명해줘")

chain = prompt | model | StrOutputParser()


async def main():
    # await를 통해서 비동기적으로 처리되는 함수가 계속 진행되지 않도록 지정
    result = await chain.ainvoke({"topic": "메이플스토리"})

    """
      Hello
      메이플스토리는 넥슨에서 개발한 2D 판타지 MMORPG로, 다양한 직업과 캐릭터를 선택해 모험을 즐길 수 있습니다. 플레이어는 몬스터를 사냥하고 퀘스트를 완료하며 경험치를 쌓아 캐릭터를 성장시키고, 친구들과 협력하여 보스를 처치하거나 파티 던전을 탐험할 수 있습니다. 게임은 귀여운 그래픽과 다양한 이벤트, 업데이트로 많은 유저들에게 사랑받고 있습니다.
    """
    print(result)


if __name__ == "__main__":
    asyncio.run(main())
```

<br>

# async batch: 비동기 배치
- `abatch()`는 여러 작업을 한꺼번에 비동기적으로 처리하는 일괄 처리 함수
- Promise.all() 이랑 비슷한듯?
```python
from dotenv import load_dotenv
from langchain_teddynote import logging
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import asyncio


load_dotenv()

logging.langsmith("langchain_test")

model = ChatOpenAI(model="gpt-4o-mini")

prompt = PromptTemplate.from_template("{topic}에 대해서 3문장으로 설명해줘")

chain = prompt | model | StrOutputParser()


async def main():
    my_batch_process = chain.abatch(
        [{"topic": "ChatGPT"}, {"topic": "Instagram"}, {"topic": "Python"}],
    )
    response = await my_batch_process

# ['ChatGPT는 OpenAI가 개발한 대화형 인공지능 모델로, 자연어 처리 기술을 기반으로 다양한 질문에 답변하고 대화를 나눌 수 있습니다. 사용자의 입력을 이해하고 그에 맞춰 유연하게 반응하여 유용한 정보를 제공하며, 창의적인 글쓰기와 문제 해결에도 도움을 줍니다. 이 모델은 기계 학습 알고리즘을 통해 지속적으로 발전하고 있으며, 여러 분야에서 유용하게 활용되고 있습니다.', '인스타그램은 사용자들이 사진과 동영상을 공유하고 소통할 수 있는 소셜 미디어 플랫폼입니다. 다양한 필터와 편집 도구를 제공하여 사용자들이 창의적으로 콘텐츠를 제작할 수 있게 합니다. 또한, 친구 및 팔로워와의 소통, 인기 있는 해시태그를 통한 발견 기능 등이 특징입니다.', 'Python은 간결하고 읽기 쉬운 문법을 가진 고급 프로그래밍 언어로, 다양한 분야에서 널리 사용됩니다. 강력한 라이브러리와 프레임워크 덕분에 데이터 분석, 웹 개발, 인공지능 등 여러 애플리케이션에 적합합니다. 또한, 활발한 커뮤니티와 풍부한 자료를 통해 배우기 쉽고, 문제가 발생했을 때 도움을 받을 수 있는 환경이 잘 조성되어 있습니다.']
    print(response)


if __name__ == "__main__":
    asyncio.run(main())
```