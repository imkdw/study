# UpstageEmbeddings
- solar-embedding-1-large-query, solar-embedding-1-large-passage 2개로 분리됨
- 4000자의 컨텍스트 길이를 지원하는데 그 이상의 경우 텍스트 분할기 사용이 필요함

```python
from langchain_upstage import UpstageEmbeddings
import numpy as np


texts = [
    "안녕, 만나서 반가워.",
    "LangChain simplifies the process of building applications with large language models",
    "랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. ",
    "LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.",
    "Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.",
]


# 쿼리전용
query_embeddings = UpstageEmbeddings(model="solar-embedding-1-large-query")

# 문장전용
passage_embeddings = UpstageEmbeddings(model="solar-embedding-1-large-passage")

# 쿼리 임베딩
embedded_query = query_embeddings.embed_query("LangChain 에 대해서 상세히 알려주세요.")

# 4096 차원
print(len(embedded_query))

# 문서 임베딩
embedded_documents = passage_embeddings.embed_documents(texts)


similarity = np.array(embedded_query) @ np.array(embedded_documents).T
sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]

# [Query] LangChain 에 대해서 알려주세요.
# ====================================
# [0] 유사도: 0.487 | LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.

# [1] 유사도: 0.465 | LangChain simplifies the process of building applications with large language models

# [2] 유사도: 0.432 | 랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다.

# [3] 유사도: 0.194 | Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.

# [4] 유사도: 0.151 | 안녕, 만나서 반가워.
print("[Query] LangChain 에 대해서 알려주세요.\n====================================")
for i, idx in enumerate(sorted_idx):
    print(f"[{i}] 유사도: {similarity[idx]:.3f} | {texts[idx]}")
    print()
```