# 임베딩
- 앞서 진행한 텍스트 분할 방법으로 나온 결과들을 청크라고 부름
- 임베딩은 이러한 청크들을 벡터 스토어라는 디비에 저장하기 전에 벡터화된 숫자 표현으로 변환하는 과정을 뜻함

<br>

# 원리
- 단락에 대해서 임베딩 변환을 하면 여러 개의 숫자(차원)으로 이루어진 벡터 값이 나옴
- 벡터 값이 1024차원이라면 여기에 1024개의 숫자가 저장되어 있다는 뜻임
- 분할했던 청크뿐만 아니라 사용자의 질문도 임베딩이 필요한데 이는 LLM은 일반 텍스트는 이해하지 못하기 때문임

<br>

# 우리가 뭘 해야할지
- 우리는 청크나 질문을 임베딩하거나 유사도를 계산할 때 어떠한 알고리즘을 쓸것인지 정해야함
- 임베딩 모델마다 생성하는 벡터의 차원이 모두 다른데 차원리 높다고해서 무조건 좋은건 아님
- 특정 RAG 프로세스에 적합한 임베딩 알고리즘은 사용목적과 데이터를 고려해서 직접 테스트하면서 선택하는게 중요함
- 보통 입문자 수준에서는 OpenAI 임베딩 모델을 자주 사용하게됨

<br>

# 입문자가 OpenAI 임베딩 모델을 사용하는 이유
- 다국어 지원과 성능이 준수함
- 하드웨어 자원의 효율적인 사용이 가능함
- 하지만 클라우드를 기반으로 API를 통해서 처리가 필요하므로 사용량에 따라서 많은 과금이 발생할 수 있음
- 만약 로컬로 고사양 컴퓨팅 자원이 없다면 GPU 자원을 임대해서 작업을 수행한 뒤 결과물을 벡터 스토어나 디비에 저장하는 방법도 고려할 수 있음