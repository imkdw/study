# CacheBackedEmbeddings
- `CacheBackedEmbeddings`는 임베딩을 한 번 수행한 후 그 결과를 파일 형태로 저장하는 방식임
- 이러한 과정에서 나온 생성된 파일을 `캐시 파일`이라고 부름
- 동일한 문서에 대해서 다시 임베딩을 시도하면 먼저 캐시 파일에 저장된 임베딩 값이 있는지 확인함
- 이후에 만약 값이 존재한다면 저장된 임베딩을 그대로 사용하므로 추가 임베딩 작업이 필요하지 않음

<br>

# 영구적으로 임베딩을 저장하는 LocalFileStore
- 임베딩 결과를 파일로 저장해서 영구적으로 보관하는 방식
- 기존 1.62초 걸리던 작업이 로컬 캐시파일로 인해 0초로 단축됨

```python
import time
from langchain.storage import LocalFileStore
from langchain_openai import OpenAIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter


# 일반 임베딩과 캐시된 임베딩 생성
embedding = OpenAIEmbeddings()

store = LocalFileStore("./cache/")

cached_embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings=embedding,
    document_embedding_cache=store,
    namespace=embedding.model,
)

print("현재 캐시된 키 개수:", len(list(store.yield_keys())))

# 문서 로드
raw_documents = TextLoader("/Users/imkdw/study/RAG 비법노트/example/maple.txt").load()

# 문자 단위로 텍스트 분할 설정
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)

# 문서 분할
documents = text_splitter.split_documents(raw_documents)

print(f"분할된 문서 개수: {len(documents)}")

# 첫 번째 실행 (캐시되지 않은 상태)
print("\n=== 첫 번째 실행 (캐시 생성) ===")
start_time = time.time()
db1 = FAISS.from_documents(documents, cached_embedder)
first_time = time.time() - start_time
print(f"첫 번째 벡터스토어 생성 시간: {first_time:.2f}초")

# 두 번째 실행 (캐시된 상태)
print("\n=== 두 번째 실행 (캐시 사용) ===")
start_time = time.time()
db2 = FAISS.from_documents(documents, cached_embedder)
second_time = time.time() - start_time
print(f"두 번째 벡터스토어 생성 시간: {second_time:.2f}초")

"""
현재 캐시된 키 개수: 0
분할된 문서 개수: 1

=== 첫 번째 실행 (캐시 생성) ===
첫 번째 벡터스토어 생성 시간: 1.62초

=== 두 번째 실행 (캐시 사용) ===
두 번째 벡터스토어 생성 시간: 0.00초

"""
```

<br>

# 비영구적으로 임베딩을 저장하는 InMemoryByteStore
- 임베딩 값을 메모리에만 저장하고 영구적으로 파일로 보관하지 않음
- 일반적으로는 영구 저장 방식을 추천하지만 비영구적인 방식은 영구적인 저장이 필요하지 않은 상황에서 유용함
- 민감한 데이터를 다루거나 특정 사용자의 데이터를 서비스 종료 후 자동으로 삭제하고자 할 때 적합함


```python
from langchain_openai import OpenAIEmbeddings
from langchain.embeddings import CacheBackedEmbeddings
from langchain_community.vectorstores.faiss import FAISS
from langchain.embeddings import CacheBackedEmbeddings
from langchain.storage import InMemoryByteStore


embedding = OpenAIEmbeddings()

store = InMemoryByteStore()

cached_embedder = CacheBackedEmbeddings.from_bytes_store(
    embedding, store, namespace=embedding.model
)
```