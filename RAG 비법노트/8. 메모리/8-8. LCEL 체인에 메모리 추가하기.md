# LCEL 체인에 메모리 추가하기
- 질문시 내 과거 내용을 토대로 답변이 가능한 체인을 만들 수 있음

```python
from dotenv import load_dotenv
from langchain_teddynote import logging

load_dotenv()
logging.langsmith("langchain_test")

# ========================================================================

from operator import itemgetter
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_openai import ChatOpenAI


model = ChatOpenAI()

# 대화형 프롬프트를 생성
# 시스템, 유저 프롬프트가 추가되고 채팅 이력으로 chat_history placeholder를 사용함
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a helpful chatbot"),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
    ]
)

# 대화 버퍼 메모리를 생성
memory = ConversationBufferMemory(return_messages=True, memory_key="chat_history")

runnable = RunnablePassthrough.assign(
    chat_history=RunnableLambda(memory.load_memory_variables)
    | itemgetter("chat_history")  # memory_key 와 동일하게 입력
)

# 캐시가 포함된 체인 생성
chain = runnable | prompt | model

input = "만나서 반갑습니다. 제 이름은 동우입니다."
response = chain.invoke({"input": input})

# 만나서 반가워요, 동우님! 무엇을 도와드릴까요?
print(response.content)

# 입력된 데이터와 응답 내용을 메모리에 저장
memory.save_context({"human": input}, {"ai": response.content})

input = "제 이름이 무엇이었는지 기억하세요?"
response = chain.invoke({"input": input})

# 네, 동우님이라고 소개해주셨죠. 어떤 도움이 필요하신가요?
print(response.content)
```
