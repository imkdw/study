# 대화 엔티티 메모리
- 대화 버퍼 윈도우 메모리, 대화 토큰 버퍼 메모리 2개의 방식은 모두 윈도우나 토큰처럼 절대적인 양을 기준으로 저장할 대화를 조정했음
- 대화가 길어지면 절대값으로 인해서 꼭 필요한 내용이 저장되지 않을수도 있음
- `ConversationEntityMemory` 는 엔티티를 추출해서 이를 기준으로 저장할 대화의 양을 지정함
  - 엔티티 : 대화나 데이터에서 특정한 의미를 가지는 핵심 정보를 의미함, 문장에서 유의한 정보로 추출될 수 있는 단위
- 이는 LLM을 사용해서 대화의 맥락을 보고 중요한 내용의 단위를 엔티티로 추출해서 엔티티에 대한 지식을 점점 축척함

```python
from dotenv import load_dotenv
from langchain_teddynote import logging

load_dotenv()
logging.langsmith("langchain_test")

# ========================================================================

from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationEntityMemory
from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE


llm = ChatOpenAI(model_name="gpt-4.1-mini", temperature=0)

conversation = ConversationChain(
    llm=llm,
    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,
    memory=ConversationEntityMemory(llm=llm),
)

# predict는 임의의 대화를 입력하고 이를 기반으로 답변을 생성함
conversation.predict(
    input="엔버와 카이저는 노바라는 같은 종족에 속한 직업입니다"
    "엔버는 도적이고 카이저는 전사입니다"
    "그들은 최근 검은마법사를 물리치고 새로운 최초의 대적자를 물리치기 위해 수련을 하고있습니다"
)

# {
#     "엔버": "엔버는 노바라는 종족에 속한 도적이며, 최근 검은마법사를 물리친 후 새로운 최초의 대적자를 상대하기 위해 수련 중이다.",
#     "카이저": "카이저는 노바라는 종족에 속한 전사이며, 최근 검은마법사를 물리친 후 새로운 최초의 대적자를 물리치기 위해 수련 중이다.",
#     "노바": "노바는 엔버와 카이저가 속한 같은 종족이다.",
#     "검은마법사": "검은마법사는 엔버와 카이저가 최근에 물리친 적이다.",
# }
print(conversation.memory.entity_store.store)
```