# 풀 테이블 스캔, 풀 인덱스 스캔

### 풀 테이블 스캔

- 인덱스를 사용하지 않고, 테이블의 데이터를 처음부터 끝까지 읽어서 처리하는 방법

#### 사용하는 경우

- 레코드가 별로 없어서 인덱스보다 풀 스캔이 빠른 경우
- WHERE, ON 조건에 적절한 조건이 없는 경우
- 인덱스 레인지 스캔이 가능하지만, 옵티마이저 판단한에 조건 일치 레코드가 너무 많은 경우

#### 풀 테이블은 디스크에서 페이지를 하나씩 읽는다?

- InnoDB는 연속된 데이터 페이지가 읽히면 백그라운드 스레드에 의해서 read ahead 작업이 진행됨
- read ahead는 어떤 영역의 데이터가 앞으로 필요하다는걸 예측해서 미리 버퍼 풀에 올려두는 작업
- 처음에는 포그라운드 스레드가 읽지만 이후에는 4개, 8개 씩 읽으면서 증가시킴
- 최대 64개의 데이터 페이지까지 읽어서 버퍼풀에저장함

#### read ahead 관련 설정

- `innodb_read_ahead_threshold`로 임계값 설정이 가능함
- 일반적인 OLTP 서비스는 기본값으로 충분하고 웨어하우스의 경우 더 낮게 설정하는것도 좋음

<br/>

### 풀 인덱스 스캔

- 쿼리에서 모든 레코드가 필요하지 않다면 풀 인덱스 스캔이 더 좋음
- read ahead는 동일하게 작동함

<br/>

### 쿼리 예시

```sql
-- 풀 인덱스 스캔
SELECT COUNT(*) FROM tb_test;

-- 풀 테이블 스캔
SELECT * FROM tb_test;
```

<br/>

# 병렬 처리

- 아무런 WHERE 조건 없이 단순하게 전체 테이블에 대해서 조회만 하는 경우 사용이 가능함
- 서버가 보유한 CPU보다 더 많이 설정하면 오히려 성능이 저하될 수 있음

```sql
mysql> set session innodb_parallel_read_threads = 1;
Query OK, 0 rows affected (0.01 sec)

mysql> select count(*) from employees;
+----------+
| count(*) |
+----------+
|   300024 |
+----------+
1 row in set (0.08 sec)

mysql> set session innodb_parallel_read_threads = 2;
Query OK, 0 rows affected (0.00 sec)

mysql> select count(*) from employees;
+----------+
| count(*) |
+----------+
|   300024 |
+----------+
1 row in set (0.04 sec)

mysql> set session innodb_parallel_read_threads = 4;
Query OK, 0 rows affected (0.00 sec)

mysql> select count(*) from employees;
+----------+
| count(*) |
+----------+
|   300024 |
+----------+
1 row in set (0.05 sec)
```

<br/>

# ORDER BY 처리(Using Filesort)

- 레코드는 1~2건 가져오는 쿼리 말곤 대부분 정렬은 필수적으로 사용함
- 정렬에는 인덱스를 사용하는 방법과, Filesort라는 별도의 처리를 이용하는 방법으로 구분함

### 인덱스 사용

- 장/단점
  - 이미 인덱스가 정렬되어 있어서 읽기만 하면 되므로 매우 빠름
  - 데이터 수정시에 추가적인 작업이 필요, 디스크 공간이 더 필요하고 버퍼 풀을 위한 메모리가 증가

<br/>

### Filesort 사용

- 장/단점
  - 인덱스를 생성하지 않아도 되서 인덱스의 단점이 곧 장점이됨
  - 정렬해야되는 레코드가 많지 않다면 메모리에서 정렬이 수행되서 빠름
  - 레코드 건수가 많아지게되면 쿼리의 응답속도가 느려짐

<br/>

### 소트 버퍼

- 정렬을 수행하기 위한 별도의 메모리 공간으로, 정렬이 필요한 경우만 할당됨
- 레코드의 크기에 따라서 가변적으로 변하고, `sort_buffer_size`로 최대값을 설정함
- 정렬해야 하는 레코드가 할당해야되는 메모리보다 크기가 크면 레코드를 여러조각으로 나누는데 이 때 임시 저장을 위해서 디스크 공간이 필요함

#### Multi Merge

- 소트 버퍼에서 정렬을 수행, 디스크에 저장하고 다시 반복하고 디스크에 저장
- 각 버퍼만큼 정렬된 레코드를 병합하면서 정렬을 수행하는데, 이를 멀티 머지라고 부름
- 위 작업은 모두 디스크의 I/O를 유발함

#### 크기 별 성능 차이

- 아무리 메모리 공간을 많이 할당해도 성능은 비슷함
- 일반적인 경우라면 56KB ~ 1MB 미만의 사이즈를 할당하는걸 권장함
- 만약 최대값을 크게 설정해서 OOM이 발생하면 OOM-Killer에 의해서 프로세스가 강제 종료됨
  - 우선순위는 메모리를 많이 사용하는 프로세스인데, 이러면 MySQL 자체가 종료될 수 있음

<br/>

### 정렬 알고리즘

- 소트 버퍼에 레코드 전체를 담을지, 정렬 기준 컬럼만 담을지에 따라 싱글패스, 투패스로 구분됨
- 쿼리가 어떤 정렬을 사용하는지는 옵티마이저 트레이스 기능으로 확인 가능함
  - `<sort_key, rowid>`: 정렬키와 레코드의 rowid만 가져와서 정렬, 투 패스
  - `<sort_key, additional_fields>`: 정렬키와 레코드 전체, 레코드 컬럼은 고정 사이즈 메모리에 저장, 싱글 패스
  - `<fixed_sort_key, packed_additional_fields>`: 정렬키와 레코드 전체, 레코드 컬럼은 가변 사이즈 메모리에 저장, 싱글 패스

```sql
mysql> SET OPTIMIZER_TRACE="enabled=on", END_MARKERS_IN_JSON="on";
Query OK, 0 rows affected (0.00 sec)

mysql> SELECT * FROM employees ORDER BY last_name LIMIT 100000,1;
+--------+------------+------------+-----------+--------+------------+
| emp_no | birth_date | first_name | last_name | gender | hire_date  |
+--------+------------+------------+-----------+--------+------------+
| 418804 | 1958-01-06 | Jacopo     | Gyimothy  | F      | 1997-06-20 |
+--------+------------+------------+-----------+--------+------------+
1 row in set (0.22 sec)

mysql> SELECT * FROM INFORMATION_SCHEMA.OPTIMIZER_TRACE \G;
*************************** 1. row ***************************
QUERY: SELECT * FROM employees ORDER BY last_name LIMIT 100000,1
TRACE: {
-- ....
  "peak_memory_used": 262144,
  "sort_algorithm": "std::stable_sort",
  "sort_mode": "<fixed_sort_key, packed_additional_fields>"
-- ...
```

<br/>

#### 싱글패스 방식

- 소트 버퍼에 정렬 기준 컬럼을 포함한 SELECT 대상이 되는 컬럼 전부를 담아서 정렬을 수행
- 정렬에 필요하지 않은 컬럼도 전부 소트 버퍼에 담아서 정렬, 이후에 그래도 결과 반환
- 일반적으로 사용하는 방식이며, 레코드의 크기나 건수가 작은 경우 빠른 성능을 보임

#### 투패스 방식

- 정렬대상 컬럼과 기본키만 소트 버퍼에 담아서 정렬
- 순서대로 정렬된 기본키를 기준으로 다시 레코드를 읽어서 결과 반환
- 큰 데이터(TEXT, BLOB) 및 레코드 크기가 `max_length_for_sort_data` 보다 크면 해당 방식을 사용함
- 정렬 대상 레코드의 크기나 건수가 상당히 많은 경우 효율적임

<br/>

### 정렬 처리 방법

- ORDER BY는 아래 방법 중 하나로 처리되고, 실행계획에 표시됨
  - 인덱스 사용 : 별도 표시 X
  - 조인에서 드라이빙 테이블만 정렬 : `Using Filesort`
  - 조인에서 조인 결과를 임시 테이블로 저장 후 정렬 : `Using Temporary; Using Filesort`
- 인덱스를 사용할 수 있다면 인덱스 순서대로 처리, 사용할 수 없다면 Filsort 사용

#### 인덱스로 정렬하기

- ORDER BY에 명시된 컬럼이 제일 먼저 읽는 테이블에 속해야한다
- ORDER BY의 순서대로 생성된 인덱스가 있어야한다
- WHERE에서 처음 읽는 컬럼에 대한 조건이 있다면, 그 조건은 ORDER BY와 같은 인덱스를 사용할 수 있어야 한다
- 해시 인덱스, 전문 검색 인덱스, R-Tree에선 사용이 불가능함
- 만약 테이블이 여러개 조인되는 경우는 nested-loop 방식의 조인에서만 사용이 가능함
- 실제 인덱스의 값이 정렬되있어서 그대로 읽기만 하면되서 빠름
- ORDER BY를 적는다고 해서 추가작업이 실행되지는 않고, 실행계획에 따라서 언제든지 바뀔 수 있으므로 가능하면 명시하는게 좋음

#### 조인의 드라이빙 테이블만 정렬

- 조인이 수행되면 레코드의 개수가 배로 불어나고 레코드의 크기도 증가하게됨
- 조인을 실행하기 전 첫번째 테이블의 레코드를 먼저 정렬한 다음 조인을 하면 정렬의 차선책이됨
- 위 방법은 첫번째로 읽히는 테이블(드라이빙 테이블)의 컬럼만으로 정렬을 수행해야함

```sql
select *
from employees e, salaries s
where s.emp_no = e.emp_no
	and e.emp_no BETWEEN 100002 AND 100010
ORDER BY e.last_name ;
```

> 아래 2가지 조건을 만족해서 옵티마이저는 employees 테이블을 드라이빙 테이블로 선정함

- WHERE의 검색조건은 employees의 기본키로 검색하면 작업량이 줄어듬
- 드리븐 테이블인 salaries의 조인 컬럼인 emp_no 컬럼에는 인덱스가 있음
- 과정
  - 인덱스 레인지 스켄을 사용해서 100002 AND 100002 조건을 만족하는 레코드 검색
  - 검색 결과를 last_name으로 정렬, 이 때 Filesort 사용
  - 정렬된 결과로 salaries 테이블과 조인을 수행해서 최종 결과를 가져옴

```json
{
  "explain\nselect *\nfrom employees e, salaries s \nwhere s.emp_no = e.emp_no \n\tand e.emp_no BETWEEN 100002 AND 100010\nORDER BY e.last_name ": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "range",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": null,
      "rows": 9,
      "filtered": 100.0,
      "Extra": "Using where; Using filesort"
    },
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "s",
      "partitions": null,
      "type": "ref",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": "realmysql.e.emp_no",
      "rows": 9,
      "filtered": 100.0,
      "Extra": null
    }
  ]
}
```

<br/>

#### 임시 테이블을 이용한 정렬

- 하나의 테이블로 부터 데이터를 가져와서 정렬하는 경우면 임시 테이블이 필요하지 않음
- 조인의 드라이빙 테이블을 정렬하는 방식 말고는 임시테이블을 통해서 다시 정렬하는 과정을 거침

```sql
explain
select *
from employees e, salaries s
where s.emp_no = e.emp_no
	and e.emp_no BETWEEN 100002 AND 100010
ORDER BY s.salary;
```

- ORDER BY 기준이 드라이빙 테이블이 아닌, 드리븐 테이블에 있는 컬럼
- 정렬 전에 salaries 테이블을 읽어야해서 조인된 데이터를 가지고 정렬을 수행해야함

```json
{
  "explain\nselect *\nfrom employees e, salaries s \nwhere s.emp_no = e.emp_no\n\tand e.emp_no BETWEEN 100002 AND 100010\nORDER BY s.salary": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "range",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": null,
      "rows": 9,
      "filtered": 100.0,
      "Extra": "Using where; Using temporary; Using filesort"
    },
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "s",
      "partitions": null,
      "type": "ref",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": "realmysql.e.emp_no",
      "rows": 9,
      "filtered": 100.0,
      "Extra": null
    }
  ]
}
```

Using temporary; Using filesort는 임시테이블에 저장하고, 다시 정렬했다는걸 의미함

<br/>

#### 정렬 처리 방법의 성능 비교

- 대부분 웹 서비스용 쿼리는 ORDER BY, LIMIT을 함께 사용함
  - LIMIT은 처리 결과의 일부만 가져오기 때문에 작업량이 줄어듬
- 하지만 GROUP BY, ORDER BY는 만족하는 조건을 LIMIT 건수로 가져와서 처리가 불가능함
  - 레코드를 모두 가져오거나 그룹핑을 통해서만 LIMIT으로 건수 제한이 가능함
- 이러한 경우 쿼리가 처리되는 방식을 스트리밍 처리, 버퍼링 처리 2가지 방식으로 구분이 가능함

#### 스트리밍 처리

- 조건에 일치하는 레코드가 검색될 때 마다 바로바로 클라이언트로 전송해주는 방식
- 클라이언트는 쿼리를 요청하고 곧바로 원했던 첫 번쨰 레코드를 전달받음
- OLTP 환경에서는 처음 응답시간이 매우 중요한데, 이 방식은 쿼리의 결과에 상관없이 빠른 응답속도를 보장함
- 또한 LIMIT을 설정하면 전체 스트리밍 처리를 통해서 받는 응답시간이 줄어듬
- 다만 디비를 사용하는 클라이언트의 API마다 다른데, JDBC의 경우 스트리밍 방식으로 처리되지만, 클라이언트에서 버퍼링하므로 응답을 모두 기다렸다가 다음 로직을 처리함
  - 이는 JDBC의 설정을 통해서 스트리밍으로도 변경이 가능함

#### 버퍼링 처리

- 쿼리를 모아서 디비단에서 일괄 가공해야 하므로 스토리이 엔진에서 모두 가져올때까지 대기함

#### 인덱스를 사용한다면?

- 인덱스를 사용한 정렬 방식에서는 LIMIT으로 제한된 건 수 만큼만 읽으면서 데이터 반환이 가능함
- 하지만 인덱스를 사용하지 못한다면 모든 연산을 다 끝내고 정렬한 후에만 반환이 가능함
- 가능하면 인덱스를 사용하는 정렬로 유도하고, 최소한 드라이빙 테이블만 정렬해도 좋은 튜닝방법임

<br/>

### 정렬 관련 상태 변수

정렬 작업의 실행 횟수를 상태 변수로 저장함

```sql
mysql> show status like 'Sort%';
+-------------------+-------+
| Variable_name     | Value |
+-------------------+-------+
| Sort_merge_passes | 0     |
| Sort_range        | 0     |
| Sort_rows         | 86    |
| Sort_scan         | 1     |
+-------------------+-------+
4 rows in set (0.00 sec)
```

- Sort_merge_passes: 멀티 머지 처리 회수
- Sort_range: 인덱스 레인지 스캔을 통한 정렬 작업 회수
- Sort_rows: 풀 테이블 스캔을 통해 검색된 결과에 대한 회수
- Sort_scan: 지금까지 정렬한 총 레코드 개수

<br/>

# GROUP BY 처리

- ORDER BY와 동일하게 쿼리가 스트리밍된 처리할 수 없게 하는 방식중 하나다
- GROUP BY에 사용된 조건은 인덱스 사용이 불가능하므로 인덱스에 대한 고민을 안해도됨

### 인덱스 스캔을 사용하는 경우(타이트 인덱스 스캔)

- 조인의 드라이빙 테이블에 속한 컬럼만 사용해서 그루핑시, GROUP BY 컬럼으로 이미 인덱스가 있다면, 그 인덱스를 차례대로 읽으면서 그루핑 작업을 수행하고 그 결과로 조인을 처리함
- 이러한 방식을 사용하면 실행계획 Extra 부분에 아무런 메세지도 나오지 않음

<br/>

### 루스 인덱스 스캔을 사용하는 경우

> 기존에 INDEX(emp_no, from_date)가 존재함

```sql
select emp_no
from salaries s
where from_date = '1985-03-01'
group by emp_no
```

#### 탐색 과정

- 인덱스를 차례대로 조회, emp_no의 첫번째 유일값 10001을 찾아냄
- 인덱스에서 emp_no가 10001이고 from_date가 '1985-03-01'인 레코드를 찾아냄
  - 이러한 방식은 `emp_no = 10001 AND from_date = '1985-03-01'`과 유사함
- emp_no = 10001 탐색이 끝나면 그 다음 유일값인 10002를 찾고 이런 과정을 반복함

<br/>

#### 루스 인덱스 사용 가능여부 판단하기

```sql
-- MIN, MAX 이외의 집함 함수가 사용되서 사용 불가능
SELECT col1, SUM(col2) FROM tb GROUP BY col1;

-- GROUP BY에 사용된 컬럼이 인덱스 구성 컬럼의 왼쪽부터 일치하지 않아서 불가
SELECT col1, col2 FROM tb GROUP BY col2, col3;

-- SELECT의 컬럼이 GROUP BY와 일치하지 않아서 사용 불가
SELECT col1, col3 FROM tb GROUP BY col1, col2;
```

<br/>

### 임시 테이블을 사용하는 GROUP BY

- 인덱스를 전혀 사용하지 못하면 이러한 방식으로 처리됨
- 내부적으로 GROUP BY절의 컬럼들로 구성된 유니크 인덱스를 가진 임시 테이블을 만들고, 중복제거와 함께 집합 함수 연산을 수행함
- 또한 자동으로 정렬을 수행하지 않지만 명시하는 경우는 정렬(Filesort)을 사용함

```sql
explain
select e.last_name, AVG(s.salary)
from employees e , salaries s
where s.emp_no = e.emp_no
GROUP BY e.last_name ;
```

```json
{
  "explain\nselect e.last_name, AVG(s.salary)\nfrom employees e , salaries s \nwhere s.emp_no = e.emp_no \nGROUP BY e.last_name ": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "ALL",
      "possible_keys": "PRIMARY",
      "key": null,
      "key_len": null,
      "ref": null,
      "rows": 300252,
      "filtered": 100.0,
      "Extra": "Using temporary"
    },
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "s",
      "partitions": null,
      "type": "ref",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": "realmysql.e.emp_no",
      "rows": 9,
      "filtered": 100.0,
      "Extra": null
    }
  ]
}
```

<br/>

# DISTINCT 처리

- 특정 컬럼의 유니크 한 값을 조회할 때 사용함
- 집합 함수와 함께 사용되는 경우와 없는 경우로 나눌 수 있음
- 인덱스를 사용하지 못할 경우는 임시테이블이 필요하지만, 실행계획에는 아무런 메세지가 나오지 않음

### SELECT DISTINCT 처리

단순한 유니크한 값만 가져오는 경우는 GROUP BY와 동일함

```sql
SELECT DISTINCT emp_no FROM tb;
SELECT emp_no FROM tb GROUP BY emp_no;
```

<br/>

#### 주의사항 1 : 단일 DISTINCT가 아님

아래 쿼리는 col1만 유니크한 값을 가져오는게 아닌 col1 + col2의 전체가 유니크한 값을 가져옴

```sql
SELECT DISTINCT col1, col2 FROM tb;
```

#### 주의사항 2 : DISINCT를 함수처럼 사용

아래 쿼리는 실제 실행될 때 함수가 제거되고 실행됨

```sql
-- 클라이언트 쿼리
SELECT DISTINCT(col1), col2 FROM tb;

-- 실제 작동 쿼리
SELECT DISTINCT col1, col2 FROM tb;
```

<br/>

### 집합 함수와 함께 사용된 DISTINCT

- 집함 함수와 함께 사용하면 집합 함수의 인자로 전달된 컬럼이 유니크한 것들을 가져옴

<br/>

#### 예제 1 : 임시 테이블 1개

- COUNT 처리를 위해서 임시테이블을 사용하는데 실행계획에는 표시되지 않음
- salary 컬럼에 유니크 인덱스가 만들어져서 레코드가 많아지면 상당히 느려질것임

```sql
explain select count(DISTINCT s.salary)
from employees e , salaries s
WHERE e.emp_no = s.emp_no
AND e.emp_no BETWEEN 100001 and 100100;
```

```json
{
  "explain select count(DISTINCT s.salary)\nfrom employees e , salaries s \nWHERE e.emp_no = s.emp_no \nAND e.emp_no BETWEEN 100001 and 100100": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "range",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": null,
      "rows": 100,
      "filtered": 100.0,
      "Extra": "Using where; Using index"
    },
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "s",
      "partitions": null,
      "type": "ref",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": "realmysql.e.emp_no",
      "rows": 9,
      "filtered": 100.0,
      "Extra": null
    }
  ]
}
```

#### 예제 2 : 임시 테이블 2개

- COUNT 처리를 위해서 2개의 임시테이블을 사용하게됨

```sql
explain select count(DISTINCT s.salary), count(DISTINCT e.last_name)
from employees e , salaries s
WHERE e.emp_no = s.emp_no
AND e.emp_no BETWEEN 100001 and 100100;
```

```json
{
  "explain select count(DISTINCT s.salary), count(DISTINCT e.last_name)\nfrom employees e , salaries s \nWHERE e.emp_no = s.emp_no \nAND e.emp_no BETWEEN 100001 and 100100": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "range",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": null,
      "rows": 100,
      "filtered": 100.0,
      "Extra": "Using where"
    },
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "s",
      "partitions": null,
      "type": "ref",
      "possible_keys": "PRIMARY",
      "key": "PRIMARY",
      "key_len": "4",
      "ref": "realmysql.e.emp_no",
      "rows": 9,
      "filtered": 100.0,
      "Extra": null
    }
  ]
}
```

만약 인덱스된 컬럼에 대해서 DISTINCT 처리를 하면 인덱스 풀 스캔 또는 레인지 스캔을 통해서 임시 테이블 없이 최적화된 처리가 가능함

```sql
explain select count(DISTINCT emp_no)  from employees e ;
```

```json
{
  "explain\nselect count(DISTINCT emp_no)  from employees e ": [
    {
      "id": 1,
      "select_type": "SIMPLE",
      "table": "e",
      "partitions": null,
      "type": "index",
      "possible_keys": "PRIMARY,ix_hiredate,ix_gender_birthdate,ix_firstname,ix_gender_birthdata",
      "key": "ix_hiredate",
      "key_len": "3",
      "ref": null,
      "rows": 300252,
      "filtered": 100.0,
      "Extra": "Using index"
    }
  ]
}
```

<br/>

# 내부 임시 테이블 활용

- 스토리지 엔진에서 받아온 데이터를 정렬, 그루핑시 내부(internal) 임시 테이블을 사용함
- 이는 `CREATE TEMPORARY TABLE` 쿼리로 만든 임시 테이블과는 다름
- 내부 임시 테이블을 쿼리의 처리가 완료되면 자동으로 삭제됨

### 메모리 임시 테이블과, 디스크 임시 테이블

- 8 버전 부터 메모리의 임시 테이블은 TempTable 엔진, 스토리지의 임시 테이블은 InnoDB를 사용
- 임시 테이블의 크기가 1GB를 넘어가면 메모리에서 디스크로 기록함

### 디스크 임시 테이블 기록 방법

#### MMAP

- 메모리의 TempTable이 1GB를 넘어가면 메모리의 임시 테이블을 MMAP 파일로 전환함
- `temptable_use_mmap`으로 MMAP 사용여부 제어가 가능함

#### InnoDB

- 때로는 임시 테이블이 메모리가 아닌 스토리지에 바로 생성되기도 함
- `internal_tmp_disk_storage_engine`으로 기록방법 제어가 가능하고, 기본은 InnoDB임

<br/>

### 임시 테이블이 필요한 쿼리

- ORDER BY와 GROUP BY에 명시된 칼럼이 다른 쿼리
- ORDER BY나 GROUP BY에 명시된 칼럼이 조인의 순서상 첫 번째 테이블이 아닌 쿼리
- DISTINCT와 ORDER BY가 동시에 쿼리에 존재하는 경우 또는 DISTINCT가 인덱스로 처리되지 못하는 쿼리
- UNIONOI나 UNION DISTINCT가 사용된 쿼리(select_type 칼럼이 UNION RESULT인 경우)
- 쿼리의 실행 계획에서 select_type이 DERIVED인 쿼리

<br/>

### 임시 테이블이 디스크에 생성되는 경우

- UNION이나 UNION ALL에서 SELECT되는 칼럼 중에서 길이가 512바이트 이상인 크기의 칼럼이 있는 경우
- GROUP BY나 DISTINCT 칼럼에서 512바이트 이상인 크기의 칼럼이 있는 경우
- 메모리 임시 테이블의 크기가 (MEMORY 스토리지 엔진에서) tmp_table_size 또는 max_heap_table_size 시스 템 변수보다 크거나 (TempTable 스토리지 엔진에서) temptable_max_ram 시스템 변수 값보다 큰 경우

<br/>

### 임시 테이블 관련 상태 변수

- Using temporary; 를 통해서 사용여부 확인은 가능하지만, 개수는 알 수 없음

```sql
mysql> show session status like 'Created_tmp%';
+-------------------------+-------+
| Variable_name           | Value |
+-------------------------+-------+
| Created_tmp_disk_tables | 1     |
| Created_tmp_files       | 0     |
| Created_tmp_tables      | 1     |
+-------------------------+-------+
3 rows in set (0.00 sec)

mysql>
```
