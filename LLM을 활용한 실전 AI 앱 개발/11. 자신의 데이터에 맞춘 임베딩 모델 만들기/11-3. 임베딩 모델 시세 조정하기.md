# 임베딩 모델 성능 평가
```python
from sentence_transformers import SentenceTransformer, InputExample
from datasets import load_dataset
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator


# 데이터 프레임에 질문과 관련이 없는 임의의 텍스트를 추가하는 함수
def add_ir_context(df):
    irrelevant_contexts = []
    for idx, row in df.iterrows():
        title = row['title']
        irrelevant_contexts.append(df.query(f"title != '{title}'").sample(n=1)['context'].values[0])
    df['irrelevant_context'] = irrelevant_contexts
    return df


klue_mrc_train = load_dataset('klue', 'mrc', split='train')
klue_mrc_test = load_dataset('klue', 'mrc', split='validation')

df_train = klue_mrc_train.to_pandas()
df_train = df_train[['title', 'question', 'context']]

df_test = klue_mrc_test.to_pandas()
df_test = df_test[['title', 'question', 'context']]

df_train_ir = add_ir_context(df_train)
df_test_ir = add_ir_context(df_test)

sentence_model = SentenceTransformer('shangrilar/klue-roberta-base-klue')

examples = []
for idx, row in df_test_ir.iterrows():
    # 질문-내용 데이터에 해당하는 질문과 컨텍스트 컬럼은 라벨을 1로 지정
    examples.append(
        InputExample(texts=[row['question'], row['context']], label=1)
    )

    # 서로 관련이 없는 질문과 무관한 컨텍스트는 라벨을 0으로 지정
    examples.append(
        InputExample(texts=[row['question'], row['irrlevant_context']], label=0)
    )


# 기본 임베딩 모델의 성능 평가
evaluator = EmbeddingSimilarityEvaluator.from_input_examples(examples)

# 0.815612312781
print(evaluator(sentence_model))
```

<br>
