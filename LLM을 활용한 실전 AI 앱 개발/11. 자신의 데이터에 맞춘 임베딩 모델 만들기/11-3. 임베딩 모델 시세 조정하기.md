# 임베딩 모델 성능 평가

```python
from sentence_transformers import SentenceTransformer, InputExample
from datasets import load_dataset
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator


# 데이터 프레임에 질문과 관련이 없는 임의의 텍스트를 추가하는 함수
def add_ir_context(df):
    irrelevant_contexts = []
    for idx, row in df.iterrows():
        title = row['title']
        irrelevant_contexts.append(df.query(f"title != '{title}'").sample(n=1)['context'].values[0])
    df['irrelevant_context'] = irrelevant_contexts
    return df


klue_mrc_train = load_dataset('klue', 'mrc', split='train')
klue_mrc_test = load_dataset('klue', 'mrc', split='validation')

df_train = klue_mrc_train.to_pandas()
df_train = df_train[['title', 'question', 'context']]

df_test = klue_mrc_test.to_pandas()
df_test = df_test[['title', 'question', 'context']]

df_train_ir = add_ir_context(df_train)
df_test_ir = add_ir_context(df_test)

sentence_model = SentenceTransformer('shangrilar/klue-roberta-base-klue')

examples = []
for idx, row in df_test_ir.iterrows():
    # 질문-내용 데이터에 해당하는 질문과 컨텍스트 컬럼은 라벨을 1로 지정
    examples.append(
        InputExample(texts=[row['question'], row['context']], label=1)
    )

    # 서로 관련이 없는 질문과 무관한 컨텍스트는 라벨을 0으로 지정
    examples.append(
        InputExample(texts=[row['question'], row['irrlevant_context']], label=0)
    )


# 기본 임베딩 모델의 성능 평가
evaluator = EmbeddingSimilarityEvaluator.from_input_examples(examples)

# 0.815612312781
print(evaluator(sentence_model))
```

<br>

# MNR 손실을 활용해 미세 조정하기

- MNR 손실은 MRC 데이터셋과 같이 데이터셋에 서로 관련이 있는 문장만 있는 경우 사용하기 좋은 손실 함수
- 하나의 배치 데이터 안에서 다른 데이터의 기사 본문을 관련이 없는 데이터로 사용해 모델을 학습시킴
- 즉 서로 관련이 있는 데이터만으로 학습 데이터를 구성하면 된다

```python
# 긍정 데이터로 학습 데이터  구성
train_examples = []
for idx, row in df_train_ir.interrows():
    train_examples.append(InputExample(texts=[row['question'], row['context']]))

# 중복 학습 데이터 제거
batch_size = 16
loader = datasets.NoDuplicatesDataLoader(train_examples, batch_size)

# MNR 손실 함수 로딩
loss = losses.MultipleNegativesRankingLoss(sentence_model)

# MRC 데이터셋으로 모델 미세조정
epochs = 1
save_path = './klue_mrc_mnr'
sentence_model.fit(
    train_objectives=[(loader, loss)],
    epochs=epochs,
    warmup_steps=100,
    output_path=save_path,
    show_progress_bar=True,
)

# 0.8601021412321
print(evaluator(sentence_model))
```
