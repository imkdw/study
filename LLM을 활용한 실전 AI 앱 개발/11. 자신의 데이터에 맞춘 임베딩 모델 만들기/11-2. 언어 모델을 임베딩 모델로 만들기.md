# 언어 모델을 임베딩 모델로 만들기
### 사전에 학습된 언어 모델을 가져와서 문장 임베딩 모델 만들기
```python
from sentence_transformers import SentenceTransformer, models

# 사용할 모델 로드
transformer_model = models.Transformer('klue/roberta-base')

# 언어 모델의 출력을 평균 내 사용하는 평균모드로 풀링 층 구성
pooling_layer = models.Pooling(
    transformer_model.get_word_embedding_dimension(),
    pooling_mode_mean_tokens=True
)

# 2개의 모듈을 결합해서 문장 임베딩 모델 생성
embedding_model = SentenceTransformer(modules=[transformer_model, pooling_layer])
```

<br>

### 실습 데이터셋 구성
```python
from datasets import load_dataset

klue_sts_train = load_dataset('klue', 'sts', split='train')
klue_sts_test = load_dataset('klue', 'sts', split='validation')

"""
sentence1, sentence2에 컬럼의 문장이 존재함
labels 컬럼에 두 문장이 얼마나 유사한지 나타내는 다양한 형식의 레이블이 존재

{
   "guid":"klue-sts-v1_train_00000",
   "source":"airbnb-rtt",
   "sentence1":"숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.",
   "sentence2":"숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.",
   "labels":{
      "label":3.7,
      "real-label":3.714285714285714,
      "binary-label":1
   }
}
"""
print(klue_sts_train[0])

"""
{
   "guid":"klue-sts-v1_dev_00000",
   "source":"airbnb-rtt",
   "sentence1":"무엇보다도 호스트분들이 너무 친절하셨습니다.",
   "sentence2":"무엇보다도, 호스트들은 매우 친절했습니다.",
   "labels":{
      "label":4.9,
      "real-label":4.857142857142857,
      "binary-label":1
   }
}
"""
print(klue_sts_test[0])
```

<br>

### 학습 데이터에서 검증 데이터셋 분리
```python
# 학습 데이터 중 10%를 학습이 잘 진행되는지 확인할 때 사용할 검증 데이터로 분리함
klue_sts_train = load_dataset('klue', 'sts', split='train').train_test_split(test_size=0.1, seed=42)
klue_sts_train, klue_sts_eval = klue_sts_train['train'], klue_sts_train['test']
```

<br>

### 라벨 정규화
```python
from sentence_transformers import InputExample

# 유사도 점수를 0~1 사이로 정규화하고 InputExample 객체에 담음
def prepare_sts_examples(dataset):
    examples = []
    for data in dataset:
        examples.append(
            # 기존 데이터셋에는 0~5점 척도로 되어있음
            InputExample(
                texts=[data['sentence1'], data['sentence2']],
                label=data['labels']['label'] / 5.0
            )
        )

    return examples

# 3개의 데이터셋을 전처리
train_examples = prepare_sts_examples(klue_sts_train)
eval_examples = prepare_sts_examples(klue_sts_eval)
test_examples = prepare_sts_examples(klue_sts_test)
```

<br>

### 배치 데이터셋과 평가객체 및 유사도 점수 비교
- 언어 모델을 그대로 사용하는 경우는 문장 임베딩 모델로서의 역할을 잘 하지 못하는 모습
```python
from torch.utils.data import DataLoader
from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator

# 배치 데이터셋
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)

# 검증을 위한 평가객체
eval_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples)
test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)

print(test_evaluator(embedding_model)) # 0.36460670798564826
```

<br>

# 유사한 문장 데이터로 임베딩 모델 학습하기
```python
from sentence_transformers import losses

num_epochs = 4
model_name = 'klue/roberta-base'
model_save_path = 'output/training_sts' + model_name.replace("/", "-")

# 학습 데이터를 문장 임베딩으로 변환하고 두 문장 사이의 코사인 유사도와 정답 유사도를 비교해서 학습 수행
train_loss = losses.CosineSimilarityLoss(model=embedding_model)

# 임베딩 모델 학습
embedding_model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    evaluator=eval_evaluator,
    epochs=num_epochs,
    evaluation_steps=1000,
    warmup_steps=100,
    output_path=model_save_path,
)

# 성능 평가
trained_embedding_model = SentenceTransformer(model_save_path)
print(test_evaluator(trained_embedding_model)) # 0.897121312312
```