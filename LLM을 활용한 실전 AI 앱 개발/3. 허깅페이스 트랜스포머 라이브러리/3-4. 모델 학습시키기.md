# 모델 학습시키기
- 허깅페이스 트랜스포터에서는 간편하게 모델 학습을 수행할 수 있도록 학습 과정을 추상화한 트레이너 API를 제공함
- 간편해서 좋지만 내부에서 어떤 과정을 통해서 학습이 진행되는지 투명하지 않음

<br>

# 데이터 준비하기
- KLUE 데이터셋의 YNAT 서브셋을 활용함, 이는 연합 뉴스 기사의 제목과 카테고리 정보가 포함되어있음
```python
from datasets import load_dataset

klue_tc_train = load_dataset('klue', 'ynat', split='train')

'''
{
  # 데이터 고유 아이디
  "guid":"ynat-v1_train_00000",

  # 뉴스 제목
  "title":"유튜브 내달 2일까지 크리에이터 지원 공간 운영",

  # 속한 카테고리 ID
  "label":3,

  # 뉴스 링크 
  "url":"https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947",

  # 뉴스 입력 시간
  "date":"2016.06.30. 오전 10:36"
}
'''
print(klue_tc_train[0])

'''
데이터셋 정보를 저장하는 features 속성에서 label명을 확인하면 어떤 카테고리가 있는지 확인이 가능함
위 예제에서 label: 3은 생활문화에 속함

['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']
'''
print(klue_tc_train.features['label'].names)
```

<br>

### 불필요 데이터 제거
```python
from datasets import load_dataset

klue_tc_train = load_dataset('klue', 'ynat', split='train')
klue_tc_train = klue_tc_train.remove_columns(['guid', 'url', 'date'])

'''
{
   "title":"유튜브 내달 2일까지 크리에이터 지원 공간 운영",
   "label":3
}
'''
print(klue_tc_train)
```

<br>

### 카테고리를 문자로 표현하기
- int2str 메소드를 통해서 라벨 인덱스를 문자로 변경할 수 있음
```python
'''
ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)
'''
print(klue_tc_train.features['label'])

'''
경제
'''
print(klue_tc_train.features['label'].int2str(1))
```

<br>

```python
from datasets import load_dataset

klue_tc_train = load_dataset('klue', 'ynat', split='train')
klue_tc_train = klue_tc_train.remove_columns(['guid', 'url', 'date'])

klue_tc_label = klue_tc_train.features['label']

def make_str_label(batch):
    batch['label_str'] = klue_tc_label.int2str(batch['label'])
    return batch

klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)

'''
{
   "title":"유튜브 내달 2일까지 크리에이터 지원 공간 운영",
   "label":3,
   "label_str":"생활문화"
}
'''
print(klue_tc_train[0])
```

<br>

### 학습 검증 테스트 데이터셋 분할하기
- 모든 학습 데이터를 사용하는 경우 양이 너무 방대할 수 있음
- 일부 데이터만 추출해서 사용하는 방법이다

```python
from datasets import load_dataset

# 학습용 데이터
klue_tc_train = load_dataset('klue', 'ynat', split='train').remove_columns(['guid', 'url', 'date'])
train_dataset = klue_tc_train.train_test_split(test_size=10000, shuffle=True, seed=42)['test']

# 검증용 데이터
klue_tc_eval = load_dataset('klue', 'ynat', split='validation')
dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)['test']

# 테스트 데이터셋
test_dataset = dataset['test']
valid_dataset = dataset['train'].train_test_split(test_size=0000, shuffle=True, seed=42)['test']
```

<br>

# 트레이너 API를 통한 학습
- 허깅페이스에서는 학습에 필요한 다양한 기능을 학습 인자만으로 쉽게 활용가능한 트레이너 API를 제공함
- 아래 예제처럼 몇 줄의 코드만으로도 텍스트 분류를 위한 데이터셋 준비 및 모델 학습이 가능하다
```python
import torch
import numpy as np
from datasets import load_dataset
from transformers import (
    Trainer,
    TrainingArguments,
    AutoModelForSequenceClassification,
    AutoTokenizer
)


model_id = 'klue/roberta-base'

def tokenize_function(examples):
    return tokenizer(examples['title'], padding="max_length", truncation=True)

# 학습용 데이터
klue_tc_train = load_dataset('klue', 'ynat', split='train')
train_dataset = klue_tc_train.train_test_split(test_size=10000, shuffle=True, seed=42)['test']

# 검증용 데이터
klue_tc_eval = load_dataset('klue', 'ynat', split='validation')
dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)['test']

# 테스트 데이터셋
test_dataset = dataset['test']
valid_dataset = dataset['train'].train_test_split(test_size=0000, shuffle=True, seed=42)['test']

model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))
tokenizer=AutoTokenizer.from_pretrained(model_id)

train_dataset = train_dataset.map(tokenize_function, batched=True)
valid_dataset = valid_dataset.map(tokenize_function, batched=True)
test_dataset = test_dataset.map(tokenize_function, batched=True)

training_args = TrainingArguments(
    # 결과 저장 폴더
    output_dir='./results',
    num_train_epochs=1,

    # 학습할 에포크 수들
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,

    # 평가 수행 빈도, epoch는 학습이 끝날때마다 검증함
    evaluation_strategy='epoch',
    learning_rate=5e-5,
    push_to_hub=False
)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return {"accuracy": (predictions == labels).mean()}


trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=valid_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)

trainer.train()

print(trainer.evaluate(test_dataset))
```

<br>

# 트레이너 API 없이 학습하기
패스..

<br>

# 학습한 모델 업로드
패스..