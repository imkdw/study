# 파인콘 클라이언트 사용법

### 파인콘 연동과 인덱스 생성

```python
from pinecone import Pinecone, ServerlessSpec

pinecone_api_key = ''

pc = Pinecone(api_key=pinecone_api_key)

"""
    인덱스(테이블) : llm-book
    스펙 : 서버리스(aws / us-east1 / 768차원)
"""
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

index = pc.Index(index_name)
```

<br>

### 임베딩 생성

```python
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from datasets import load_dataset

pinecone_api_key = ''
pc = Pinecone(api_key=pinecone_api_key)
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

index = pc.Index(index_name)

sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
klue_dp_train = load_dataset('klue', 'dp', split='train[:100]')

embeddings = sentence_model.encode(klue_dp_train['sentence'])
```

<br>

### 데이터 형식 변환 및 인덱스에 저장

```python
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from datasets import load_dataset

pinecone_api_key = ''
pc = Pinecone(api_key=pinecone_api_key)
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

index = pc.Index(index_name)

sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
klue_dp_train = load_dataset('klue', 'dp', split='train[:100]')

embeddings = sentence_model.encode(klue_dp_train['sentence'])

# 파이썬 기본 데이터 타입인 리스트로 변경
embeddings = embeddings.tolist()

# 파인콘에 추가할 데이터 형식으로 변환
insert_data = []
for idx, (embedding, text) in enumerate(zip(embeddings, klue_dp_train['sentence'])):
  insert_data.append({"id": str(idx), "values": embedding, "metadata": {'text': text}})

# 임베딩 데이터를 인덱스에 저장
upsert_response = index.upsert(vectors = insert_data, namespace='llm-book-sub')
```

<br>

### 인덱스 검색 수행

```python
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from datasets import load_dataset

pinecone_api_key = ''
pc = Pinecone(api_key=pinecone_api_key)
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

index = pc.Index(index_name)

sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
klue_dp_train = load_dataset('klue', 'dp', split='train[:100]')

embeddings = sentence_model.encode(klue_dp_train['sentence']).tolist()

query_response = index.query(
    namespace='llm-book-sub',  # 검색할 네임스페이스
    top_k=10,  # 몇 개의 결과를 반환할지
    include_values=True,  # 벡터 임베딩 반환 여부
    include_metadata=True,  # 메타 데이터 반환 여부
    vector=embeddings[0]  # 검색할 벡터 임베딩
)

"""
{
    'matches': [
        {
            'id': '0',
            'score': 0.999613702,
            'metadata': {
                'text': '해당 그림을 보면 디즈니 공주들이 브리트니 스피어스의 앨범이나 뮤직비디오, '
                        '화보 속 모습을 똑같이 재연했다.'
            },
            'values': [
                -1.10073376,
                0.220478311,
                0.742353678,
                0.407552451,
                0.408453524,
                # ... (데이터가 너무 길어 생략)
                -0.481126428,
                0.350117356
            ]
        }
    ],
    'namespace': 'llm-book-sub',
    'usage': {
        'read_units': 1
    }
}
"""
print(query_response)
```

<br>

### 수정 및 삭제

```python
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from datasets import load_dataset

pinecone_api_key = ''
pc = Pinecone(api_key=pinecone_api_key)
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

index = pc.Index(index_name)

sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')
klue_dp_train = load_dataset('klue', 'dp', split='train[:100]')

embeddings = sentence_model.encode(klue_dp_train['sentence']).tolist()

new_text = '변경할 새로운 텍스트'
new_embedding = sentence_model.encode(new_text).tolist()

# 수정
update_response = index.update(
    id= '기존_문서_id',
    values=new_embedding,
    set_metadata={'text': new_text},
    namespace='llm-book-sub'
)

# 삭제
delete_response = index.delete(ids=['기존_문서_id'], namespace='llm-book-sub')
```

<br>

# 라마인덱스에서 벡터디비 변경하기

- 라마인덱스는 기본 벡터 디비를 사용함
- 라마인덱스는 다양한 벡터 디비와 쉽게 통합할 수 있는 기능을 제공해줌

```python
from pinecone import Pinecone, ServerlessSpec
from llama_index.vector_stores.pinecone import PineconeVectorStore
from llama_index.core import StorageContext
from llama_index.core import Document, VectorStoreIndex
from datasets import load_dataset
import os

pinecone_api_key = ''
pc = Pinecone(api_key=pinecone_api_key)
index_name = "llm-book"

if not pc.has_index(index_name):
    pc.create_index(
        name=index_name,
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
        dimension=768
    )

pinecone_index = pc.Index(index_name)

# documents 생성
os.environ["OPENAI_API_KEY"] = ""
dataset = load_dataset('klue', 'mrc', split='train')
text_list = dataset[:100]['context']
documents = [Document(text=t) for t in text_list]

# 벡터 디비를 pinecone으로 변경
vector_store = PineconeVectorStore(pinecone_index=pinecone_index)
storage_context = StorageContext.from_defaults(vector_store=vector_store)
pinecone_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)
```
