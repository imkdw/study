# HNSW 인덱스의 핵심 파라미터

- `m` : 하나의 벡터에 연결하는 최소 연결 수
- `ef_construction` : 색인 과정에서 가장 가까운 M개를 선택하기 위해 저장하는 후보의 수
- `ef_search` : 검색 과정에서 가장 가까운 K개를 선택할 때 저장하는 후보의 수
- 위 3가지 파라미터로 메모리 사용량, 색인 시간, 재현율, 검색 시간이 달라지게된다

<br>

# 파라미터 m 이해하기

- HNSW에서 추가하는 임베딩 벡터에 연결하는 간선의 수다
- 벡터에 연결되는 간선이 많을수록 그래프가 더 촘촘하게 연결되므로 검색의 품질(재현율)이 좋아진다
- 하지만 더 많은 연결을 생성하고 정보를 저장해야 하므로 메모리 사용량이 커지고 색인 시간이 길어진다

<br>

### 테스트

- 간선의 수가 늘어날수록 색인시간, 검색시간, 메모리 사용량이 증가한다
- 하지만 검색 결과가 간선이 제일 많을때 높게 측정된다
- 보통 5~48 정도의 값을 사용하며 메모리가 허용하는 선에서는 값을 키워서 검색 품질을 높이는것이 유리하다

```python
import numpy as np
import time
import faiss
from faiss.contrib.datasets import DatasetSIFT1M
import psutil

def get_memory_usage_mb():
    process = psutil.Process()
    memory_info = process.memory_info()
    return memory_info.rss / (1024 * 1024)

ds = DatasetSIFT1M()

xq = ds.get_queries()
xb = ds.get_database()
gt = ds.get_groundtruth()


k=1
d = xq.shape[1]
nq = 1000
xq = xq[:nq]

for m in [8, 16, 32, 64]:
    # 간선의 수를 늘려가면서 인덱싱 진행
    index = faiss.IndexHNSWFlat(d, m)
    time.sleep(3)
    start_memory = get_memory_usage_mb()
    start_index = time.time()
    index.add(xb)
    end_memory = get_memory_usage_mb()
    end_index = time.time()
    print(f"M: {m} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB")

    t0 = time.time()
    D, I = index.search(xq, k)
    t1 = time.time()

    # 재현율 계산
    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)
    print(f"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}")

"""
M: 8 - 색인 시간: 13.017822027206421 s, 메모리 사용량: 734.703125 MB
0.006 ms per query, R@1 0.678

M: 16 - 색인 시간: 14.658699035644531 s, 메모리 사용량: 440.71875 MB
0.009 ms per query, R@1 0.777

M: 32 - 색인 시간: 26.44316291809082 s, 메모리 사용량: 689.96875 MB
0.011 ms per query, R@1 0.904

M: 64 - 색인 시간: 33.052529096603394 s, 메모리 사용량: 984.578125 MB
0.015 ms per query, R@1 0.937
"""
```

<br>

# 파라미터 ef_construction 이해하기

- 인덱스(테이블)에 새로운 벡터를 추가하는 경우 검색할 때와 유사하게 추가한 벡터와 가장 가까운 벡터를 탐색한다
- 이 때 `ef_construction` 파라미터는 추가할 벡터와 가장 가까운 벡터를 탐색할 때 저장하는 후보의 수를 결정한다
- 값이 클수록 더 많은 후보를 탐색하기 때문에 실제로 추가한 벡터와 가장 가까운 벡터를 선택할 가능성이 높아진다
- 이는 생성하는 그래프틔 품질이 좋아진다는 것을 의미한다
- 더 많은 후보를 탐색하는 경우 색인 시간이 증가하지만 메모리 사용량과 검색 시간은 크게 영향받지 않는다

<br>

### 테스트

- 색인시간은 거의 배수로 증가하는 반면 메모리 사용량이나 재현율은 큰 차이가 존재하지않는다
- 재현율이 더 낮아질수도 있는 이유는 그래프 생성시 랜덤성이 들어가기 때문에 결과가 언제나 의도한대로 나타나진 않는다

```python
import numpy as np
import time
import faiss
from faiss.contrib.datasets import DatasetSIFT1M
import psutil


def get_memory_usage_mb():
    process = psutil.Process()
    memory_info = process.memory_info()
    return memory_info.rss / (1024 * 1024)


ds = DatasetSIFT1M()

xq = ds.get_queries()
xb = ds.get_database()
gt = ds.get_groundtruth()

k = 1
d = xq.shape[1]
nq = 1000
xq = xq[:nq]

for ef_construction in [40, 80, 160, 320]:
    # 간선의 수(m)는 32로 고정값 사용
    index = faiss.IndexHNSWFlat(d, 32)
    index.hnsw.efConstruction = ef_construction
    time.sleep(3)
    start_memory = get_memory_usage_mb()
    start_index = time.time()
    index.add(xb)
    end_memory = get_memory_usage_mb()
    end_index = time.time()
    print(
        f"efConstruction: {ef_construction} - 색인 시간: {end_index - start_index} s, 메모리 사용량: {end_memory - start_memory} MB")

    t0 = time.time()
    D, I = index.search(xq, k)
    t1 = time.time()

    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)
    print(f"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}")

"""
efConstruction: 40 - 색인 시간: 27.91890025138855 s, 메모리 사용량: 894.71875 MB
0.012 ms per query, R@1 0.898

efConstruction: 80 - 색인 시간: 34.28960394859314 s, 메모리 사용량: 750.90625 MB
0.009 ms per query, R@1 0.874

efConstruction: 160 - 색인 시간: 62.412193775177 s, 메모리 사용량: 701.890625 MB
0.013 ms per query, R@1 0.894

efConstruction: 320 - 색인 시간: 117.34040808677673 s, 메모리 사용량: 734.875 MB
0.012 ms per query, R@1 0.908
"""
```

<br>

# 파라미터 ef_search 이해하기

- ef_construction이 색인 단게에서 후보군의 크기를 결정한다면 ef_search는 검색 단계에서 후보군의 크기를 결정한다
- 후보군이 커지면 더 많은 벡터를 탐색하고 결과적으로 재현율이 높아지게된다
- 하지만 더 많은 벡터를 탐색하는 경우 검색 시간이 길어지게된다

<br>

### 테스트

- 후보군이 커질수록 검색 시간이 증가하는 것을 확인할 수 있다

```python
import numpy as np
import time
import faiss
from faiss.contrib.datasets import DatasetSIFT1M
import psutil


def get_memory_usage_mb():
    process = psutil.Process()
    memory_info = process.memory_info()
    return memory_info.rss / (1024 * 1024)


ds = DatasetSIFT1M()

xq = ds.get_queries()
xb = ds.get_database()
gt = ds.get_groundtruth()

k = 1
d = xq.shape[1]
nq = 1000
xq = xq[:nq]

for ef_search in [16, 32, 64, 128]:
    index = faiss.IndexHNSWFlat(d, 32)
    index.hnsw.efSearch = ef_search
    start_memory = get_memory_usage_mb()
    start_index = time.time()
    index.add(xb)
    end_memory = get_memory_usage_mb()
    end_index = time.time()
    t0 = time.time()
    D, I = index.search(xq, k)
    t1 = time.time()

    recall_at_1 = np.equal(I, gt[:nq, :1]).sum() / float(nq)
    print(f"{(t1 - t0) * 1000.0 / nq:.3f} ms per query, R@1 {recall_at_1:.3f}")

"""

0.012 ms per query, R@1 0.902
0.016 ms per query, R@1 0.958
0.030 ms per query, R@1 0.980
0.054 ms per query, R@1 0.995
"""
```
