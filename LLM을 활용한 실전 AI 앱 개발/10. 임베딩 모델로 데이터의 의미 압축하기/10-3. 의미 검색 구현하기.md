# 의미 검색
- 의미 검색은 단순히 키워드 매칭을 통한 검색이 아닌 밀집 임베딩을 이용해서 문장이나 문서의 의미를 고려한 검색을 수행하는것을 말함

<br>

# 의미 검색 구현하기
- 의미 검색을 구현하기 위해서는 검색 쿼리 문장을 문장 임베딩으로 변환학 인덱스에서 검색하면됨
- 의미 검색은 키워드 검색과 달리 동일한 키워드가 사용되지 않아도 의미적 유사성이 있다면 가깝게 평가한다는 장점이 있음
```python
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import faiss

# 1000개의 데이터만 선택
klue_mrc_dataset = load_dataset('klue', 'mrc', split='train').train_test_split(train_size=1000, shuffle=False)['train']
sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

# 문장 임베딩으로 변환
embeddings = sentence_model.encode(klue_mrc_dataset['context'])

# KNN 알고리즘을 활용해서 인덱스 생성, 이는 단순하게 RDBMS 테이블처럼 데이터를 저장할 공간임
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

# 검색 쿼리 문장을 문장 임베딩으로 검색
query = '이번 연도에는 언제 비가 많이 올까?'
query_embedding = sentence_model.encode([query])

# 인덱스에서 문장 임베딩으로 검색, 3은 검색할 데이터의 개수
distances, indices = index.search(query_embedding, 3)

"""
(정답) 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 
(오답) 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그
(오답) 연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그
"""
for inx in indices[0]:
    print(klue_mrc_dataset['context'][inx][:50])
```

<br>

### 의미 검색의 한계
- 의미 검색은 키워드가 동일하지 않아도 의미가 유사하면 찾을 수 있다는 장점이 있음
- 하지만 관련성이 떨어지는 검색 결과가 나오기도 한다는 단점이 존재함
- 이러한 의미 검색의 한계를 보완하기 위해서 `하이브리드 검색`이 존재함
```python
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import faiss

klue_mrc_dataset = load_dataset('klue', 'mrc', split='train').train_test_split(train_size=1000, shuffle=False)['train']
sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

embeddings = sentence_model.encode(klue_mrc_dataset['context'])

index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)

# 로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?
query = klue_mrc_dataset[3]['question']
query_embedding = sentence_model.encode([query])

# 인덱스에서 문장 임베딩으로 검색, 3은 검색할 데이터의 개수
distances, indices = index.search(query_embedding, 3)

"""
(오답) 태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 
(오답) 태평양 전쟁 중 뉴기니 방면에서 진공 작전을 실시해 온 더글러스 맥아더 장군을 사령관으로 
(정답) 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스
"""
for inx in indices[0]:
    print(klue_mrc_dataset['context'][inx][:50])
```

<br>

# 라마인덱스에서 Setence-Transformers 사용하기
- 라마인덱스는 기본적으로 `text-embedding-ada-002`를 사용하는데 이는 OpenAI API만 설정하면 기본으로 사용함
- HuggingFaceEmbedding 클래스에 모델 이름으로 모델 저장소 이름을 입력하면 해당 모델 사용이 가능함
```python
from datasets import load_dataset
from llama_index.core import VectorStoreIndex, ServiceContext, Document
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

embed_model = HuggingFaceEmbedding(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)

# 로컬 모델을 활용하는 방법
# service_context = ServiceContext.from_defaults(embed_model="local")

klue_mrc_dataset = load_dataset('klue', 'mrc', split='train').train_test_split(train_size=1000, shuffle=False)['train']
text_list = klue_mrc_dataset[:100]['context']
documents = [Document(text=t) for t in text_list]

index_llama = VectorStoreIndex.from_documents(
    documents, service_context=service_context,
)
```