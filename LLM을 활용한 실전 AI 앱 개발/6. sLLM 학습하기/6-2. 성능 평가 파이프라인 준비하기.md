# 평가 데이터셋 구축
- https://huggingface.co/datasets/shangrilar/ko_text2sql/viewer/default/test

<br>

# SQL 생성 프롬프트
- LLM이 SQL을 생성하도록 하기 위해서는 지시사항과 데이터를 포함한 프롬프트 준비가 필요함
```python
def make_prompt(ddl, question, query=''):
    prompt = f"""
    당신은 SQL을 생성하는 SQL 봇입니다.
    DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.

    ### DDL:
    {ddl}

    ### Question:
    {question}

    ### SQL:
    {query}
    
    """
    return prompt
```

<br>

### 프롬프트 데이터 예시
```
당신은 SQL을 생성하는 SQL 봇입니다.
DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.

### DDL:
create table messages (
    "message_id" SERIAL PRIMARY KEY,
    "conversation_id" INT NOT NULL,
    "sender_id" INT NOT NULL,
    "content" TEXT,
    "timestamp" TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    "read" BOOLEAN DEFAULT FALSE,
    FOREIGN KEY ("conversation_id") REFERENCES conversations (conversation_id)
    FOREIGN KEY ("sender_id") REFERENCES users("user_id")
)


### Question:
messages 테이블에서 모든 데이터를 조회해 줘

### SQL:
select * from messages
```

<br>

### GPT-4 평가 프롬프트와 코드 준비
- 평가데이터가 적다면 큰 문제가 되진 않지만 데이터셋이 큰 경우 openai-cookbook에서 제공하는 rate limit 제어를 사용해야한다
```python
import json
import pandas as pd
from pathlib import Path

def make_requests_for_gpt_evaluation(df, filename, dir='requests'):
  if not Path(dir).exists():
      Path(dir).mkdir(parents=True)
  prompts = []
  for idx, row in df.iterrows():
      prompts.append("""Based on below DDL and Question, evaluate gen_sql can resolve Question. If gen_sql and gt_sql do equal job, return "yes" else return "no". Output JSON Format: {"resolve_yn": ""}""" + f"""

DDL: {row['context']}
Question: {row['question']}
gt_sql: {row['answer']}
gen_sql: {row['gen_sql']}"""
)

  jobs = [{"model": "gpt-4-turbo-preview", "response_format" : { "type": "json_object" }, "messages": [{"role": "system", "content": prompt}]} for prompt in prompts]
  with open(Path(dir, filename), "w") as f:
      for job in jobs:
          json_string = json.dumps(job)
          f.write(json_string + "\n")
```

<br>

### 비동기 요청 명령
```python
import os
os.environ["OPENAI_API_KEY"] = "자신의 OpenAI API 키 입력"

python api_request_parallel_processor.py \
  --requests_filepath {요청 파일 경로} \
  --save_filepath {생성할 결과 파일 경로} \
  --request_url https://api.openai.com/v1/chat/completions \
  --max_requests_per_minute 300 \
  --max_tokens_per_minute 100000 \
  --token_encoding_name cl100k_base \
  --max_attempts 5 \
  --logging_level 20
```

<br>

### jsonl -> csv 변환
```python
def change_jsonl_to_csv(input_file, output_file, prompt_column="prompt", response_column="response"):
    prompts = []
    responses = []
    with open(input_file, 'r') as json_file:
        for data in json_file:
            prompts.append(json.loads(data)[0]['messages'][0]['content'])
            responses.append(json.loads(data)[1]['choices'][0]['message']['content'])

    df = pd.DataFrame({prompt_column: prompts, response_column: responses})
    df.to_csv(output_file, index=False)
    return df
```
