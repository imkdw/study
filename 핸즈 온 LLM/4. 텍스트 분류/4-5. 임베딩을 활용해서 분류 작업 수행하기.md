# 임베딩을 활용해서 분류 작업 수행하기
- 이전의 내용에서는 감성 분석 작업에 특화된 사전 훈련된 모델을 사용했음
- 하지만 만약 이러한 모델이 없다면 표현 모델을 직접 파인튜닝 해야될지에 대한 대답은 `X`임
- 충분한 컴퓨팅 자원이 있다면 가능하겠지만 누구나 가지고 있진 않음
- 이것이 범용 임베딩 모델이 필요한 이유임

<br>

# 지도 학습 분류
- 분류 작업에 표현 모델을 바로 사용하는게 아니라 임베딩 모델을 사용해서 특성을 생성하는 방식임
- 이런 특성을 분류기에 주입할 수 있음
- 주된 이점은 비용이 많이 들 수 있는 임베딩 모델을 파인튜닝할 필요가 없고 CPU에서 `로지스틱 회귀`와 같은 분류기를 훈련하면됨

<br>

### 단계별 구분
- 먼저 임베딩 모델을 사용해서 텍스트 입력을 임베딩으로 변환시킴, 이 모델은 동결되며 훈련 과정 동안 업데이트 되지 않음
- 사전에 훈련된 임베딩 모델을 활용하는데 인기가 높은 `sentence-transformers`를 통해서 수행이 가능함
- 임베딩은 입력 텍스트의 수치 표현인데, 임베딩의 차원은 임베딩 모델에 따라서 다름
- 임베딩을 분류기에 입력 특성으로 제공하는데, 이 분류기는 훈련이 가능하고 로지스틱 회귀뿐만 아니라 분류 작업을 수행할 수 있다면 어떠한 모델도 가능함

<br>

### 임베딩 모델로 특성 생성하고 주입하기
- F1 점수 0.85점이라는 점수가 나옴
- 이는 임베딩 모델을 동결한 채 간단한 분류기를 훈련할 수 있다는 가능성을 보여줌
```python
from transformers import pipeline
import numpy as np
from tqdm import tqdm
from transformers.pipelines.pt_utils import KeyDataset
from sklearn.metrics import classification_report
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
from sklearn.linear_model import LogisticRegression

# 영화 리뷰 데이터셋 로딩
data = load_dataset("rotten_tomatoes")


# 분류 리포트를 만드는 함수
def evaluate_performance(y_true, y_pred):
    performance = classification_report(
        y_true, y_pred,
        target_names=["Negative Review", "Positive Review"]
    )
    print(performance)


# 텍스트를 임베딩으로 변환하기
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
train_embeddings = model.encode(data["train"]['text'], show_progress_bar=True)
test_embeddings = model.encode(data["test"]['text'], show_progress_bar=True)

"""
(8530, 768)

8530개의 문서가 768차원으로 임베딩됨
"""
print(train_embeddings.shape)

# 훈련 세트의 임베딩으로 로지스틱 회귀 모델을 훈련시킴
clf = LogisticRegression(random_state=42)
clf.fit(train_embeddings, data["train"]["label"])

# 추론 진행
y_pred = clf.predict(test_embeddings)

"""
                 precision    recall  f1-score   support

Negative Review       0.85      0.86      0.85       533
Positive Review       0.86      0.85      0.85       533

       accuracy                           0.85      1066
      macro avg       0.85      0.85      0.85      1066
   weighted avg       0.85      0.85      0.85      1066
"""
evaluate_performance(data["test"]["label"], y_pred)
```

<br>

### 분류기를 사용하지 않고 코사인 유사도를 적용하기
- 분류기 대신 클래스별 임베딩을 평균하고 코사인 유사도를 적용해서 무서와 가장 잘 맞는 클래스 예측하는 방법임
```python
from transformers import pipeline
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics.pairwise import cosine_similarity

# 영화 리뷰 데이터셋 로딩
data = load_dataset("rotten_tomatoes")


# 분류 리포트를 만드는 함수
def evaluate_performance(y_true, y_pred):
    performance = classification_report(
        y_true, y_pred,
        target_names=["Negative Review", "Positive Review"]
    )
    print(performance)


# 텍스트를 임베딩으로 변환하기
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
train_embeddings = model.encode(data["train"]['text'], show_progress_bar=True)
test_embeddings = model.encode(data["test"]['text'], show_progress_bar=True)

# 타겟 레이블에 대한 문서의 임베딩을 모듀 평균해서 타겟 임베딩을 생성함
df = pd.DataFrame(np.hstack([train_embeddings, np.array(data["train"]["label"]).reshape(-1, 1)]))
averaged_target_embeddings = df.groupby(768).mean().values

# 테스트 임베딩과 가장 가까운 타겟 임베딩을 조회
sim_matrix = cosine_similarity(test_embeddings, averaged_target_embeddings)
y_pred = np.argmax(sim_matrix, axis=1)

"""
                 precision    recall  f1-score   support

Negative Review       0.85      0.84      0.84       533
Positive Review       0.84      0.85      0.84       533

       accuracy                           0.84      1066
      macro avg       0.84      0.84      0.84      1066
   weighted avg       0.84      0.84      0.84      1066
"""
evaluate_performance(data["test"]["label"], y_pred)
```

<br>

# 데이터에 레이블이 없는 경우
- 레이블이 있는 데이터를 모으는 것은 많은 인력이 동원되는 노동집약적인 작업임
- 이게 실제로 가치가 있는지 테스트를 위해서 레이블이 없는 데이터로 작업의 가능성을 가늠해 보는 `제로샷 분류`를 수행할 수 있음
- 제로샷 분류는 해당 데이터에서 훈련되지 않았더라도 입력 데이터의 레이블을 예측할 수 있음
- 제로샷 분류에서는 레이블을 가진 데이터가 없고 레이블 자체만 존재함, 여기서 제로샷 모델은 입력이 후보 레이블과 어떻게 관련이 있는지 결정함
- 이 때 레이블이 나타내야 하는 것을 기반으로 레이블 설명을 만들 수 있는데 예를 덜면 영화 리뷰에 대한 음성 레이블은 `이 리뷰는 음싱 리뷰입니다`라고 설명이 가능함

<br>

### 레이블 임베딩 만들기
- 문서에 레이블을 할당하기 위해서 `코사인 유사도`를 문서-레이블 쌍에 적용할 수 있음
- 이는 두 벡터 사이 각도의 코사인 값임
- 레이블이 있는 데이터를 전혀 사용하지 않고도 0.78이라는 괜찮은 점수가 나온걸 볼 수 있음

```python
from transformers import pipeline
from datasets import load_dataset
from sentence_transformers import SentenceTransformer
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics.pairwise import cosine_similarity

# 영화 리뷰 데이터셋 로딩
data = load_dataset("rotten_tomatoes")


# 분류 리포트를 만드는 함수
def evaluate_performance(y_true, y_pred):
    performance = classification_report(
        y_true, y_pred,
        target_names=["Negative Review", "Positive Review"]
    )
    print(performance)


# 텍스트를 임베딩으로 변환하기
model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')
train_embeddings = model.encode(data["train"]['text'], show_progress_bar=True)
test_embeddings = model.encode(data["test"]['text'], show_progress_bar=True)

# 트위터 데이터셋으로 학습된 감성 평가 모델 로딩
model_path = "cardiffnlp/twitter-roberta-base-sentiment-latest"
pipe = pipeline(
    model=model_path,
    tokenizer=model_path,
    return_all_scores=True,
    device="cpu"
)

# 레이블 임베딩 생성
label_embeddings = model.encode(["A negative review", "A positive review"])

# 각 문서와 가장 잘 맞는 레이블 조회
sim_matrix = cosine_similarity(test_embeddings, label_embeddings)
y_pred = np.argmax(sim_matrix, axis=1)

"""
                 precision    recall  f1-score   support

Negative Review       0.78      0.77      0.78       533
Positive Review       0.77      0.79      0.78       533

       accuracy                           0.78      1066
      macro avg       0.78      0.78      0.78      1066
   weighted avg       0.78      0.78      0.78      1066
"""
evaluate_performance(data["test"]["label"], y_pred)
```