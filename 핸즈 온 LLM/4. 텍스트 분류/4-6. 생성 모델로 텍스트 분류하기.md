# 생성 모델로 텍스트 분류하기
- GPT 모델 같은 생성 언어 모델을 사용한 분류는 어떤 텍스트를 입력받아서 텍스트를 생성함
- `시퀀스-투-시퀀스` 모델이라고 부르며 이는 클래스를 출력하는 작업에 특화된 모델과 뚜렷하게 대조됨
- 이런 생성형 모델은 다양한 작업으로 훈련되지만 현재 주어진 문제를 즉시 수행하지는 못함
  - 예를 들면 맥락에 아무런것도 전달하지 못하고 영화 데이터만 전달해서는 모델이 뭘 해야할지 모름
- 모델이 맥락을 이해하도록 돕고 원하는 답을 찾게 유도해야하는데 이 안내과정을 모델에게 제공되는 `명령` 또는 `프롬프트`라고 부름
- 원하는 출력을 얻을 수 있도록 프롬프트를 반복적으로 개선하는걸 `프롬프트 엔지니어링`이라고 부름

<br>

# T5(Text-to-Text Transfer Transformer) 모델 사용하기
- 원본 트랜스포머와 비슷하게 `12개의 인코더`와 `12개의 디코더`로 구성됨
- 이러한 구조는 `마스크드 언어 모델링`을 통해서 훈련되었음
  - 훈련 첫 단게에서 개별 토큰을 마스킹하는게 아닌 일련의 토큰을 마스킹 처리하는 모델링 방법임
- 베이스 모델 파인튜닝 단계에서 마법이 일어나는데 하나의 특정 작업을 위해서 파인튜닝하는게 아닌 각각의 작업을 `시퀀스-투-시퀀스` 작업으로 변환하는 동시에 훈련함
- 이렇게 다양한 작업을 활용해서 만든 모델이 `Flan-T5 모델`임

<br>

### T5 모델 사용하기
- 주로 사용하는 모델은 `text2text-generation` 모델이 있음
- 모델에 단지 텍스트를 주입하고 감성 분석 결과를 출력하는걸 기대할 수 없으므로 모델에게 지시(프롬프트)가 필요함
- 이전에 사용했던 감성 분석용 모델의 점수(0.8)보다 0.03점 더 높은 결과를 볼 수 있음
```python
from transformers import pipeline
from tqdm import tqdm
from transformers.pipelines.pt_utils import KeyDataset
from datasets import load_dataset
from sklearn.metrics import classification_report

# 영화 리뷰 데이터셋 로딩
data = load_dataset("rotten_tomatoes")


# 분류 리포트를 만드는 함수
def evaluate_performance(y_true, y_pred):
    performance = classification_report(
        y_true, y_pred,
        target_names=["Negative Review", "Positive Review"]
    )
    print(performance)


pipe = pipeline(
    "text2text-generation",
    model="google/flan-t5-small",
    device="cpu"
)

prompt = "Is the following sentence positive or negative?"
data = data.map(lambda example: {"t5": prompt + example["text"]})

y_pred = []

for output in tqdm(pipe(KeyDataset(data["test"], "t5")), total=len(data["test"])):
    text = output[0]["generated_text"]
    y_pred.append(0 if text == "negative" else 1)

"""
                 precision    recall  f1-score   support

Negative Review       0.83      0.84      0.83       533
Positive Review       0.84      0.83      0.83       533

       accuracy                           0.83      1066
      macro avg       0.83      0.83      0.83      1066
   weighted avg       0.83      0.83      0.83      1066
"""
evaluate_performance(data["test"]["label"], y_pred)
```

<br>

# ChatGPT로 분류하기
### GPT의 구조
- ChatGPT 3.5의 구조는 알려지지 않았지만 이름으로 부터 `디코더 기반일 것이라 추측`할 수 있음
- OpenAI는 대략적인 훈련 과정을 공개했는데 그 내부에는 `선호도 튜닝(preference tuning)`이라는 중요한 구성요소가 포함됨

<br>

### 선호도 튜닝
- 우선 먼저 프롬프트에 대해 기대하는 출력을 수동으로 만듬, 이 데이터를 통해서 첫 번째 버전을 생성함
- 이후에 만들어진 모델을 사용해서 여러 출력을 만들고 가장 나쁜것에서 가장 좋은것까지 수동으로 순위를 매김
- 이러한 선호도 데이터를 통해서 최종 모델을 생성함
- 이러한 방식의 주요 이점은 데이터가 표현하는 뉘앙스인데 좋은 출력과 나쁜 출력의 차이점을 알려줘서 생성 모델이 사람의 기호에 맞는 출력을 생성하는 방법을 학습할 수 있음

<br>

### GPT로 분류하기
