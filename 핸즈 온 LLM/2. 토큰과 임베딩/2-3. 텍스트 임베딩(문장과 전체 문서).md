# 텍스트 임베딩(문장과 전체 문서)
- LLM이 주로 토큰 임베딩으로 작동하는데 많은 LLM앱은 전체 문장, 문당, 텍스트 문서를 다뤄야함
- 하나의 벡터로 토큰보다 긴 텍스트를 표현하는 `텍스트 임베딩`을 만드는 모델이 등장함

<br>

### 텍스트 임베딩 모델
- 텍스트 조각을 입력받아 텍스트를 표현하고 유용한 어떤 형태로 의미를 포착하는 하나의 벡터를 만드는 모델
- 가장 많이 사용하는 방법은 모델이 만든 토큰 임베딩 값의 평균을 구하는 방법임
- 하지만 고품질 텍스트 임베딩 모델을 얻으려면 텍스트 임베딩 작업에서 특별하게 훈련하곤함
- huggingface에서 제공하는 `setence-transformers` 라이브러리를 통해서 텍스트 임베딩 생성이 가능함

<br>

### sentence-transformers 라이브러리로 텍스트 임베딩 만들기
- 벡터 임베딩의 값 개수 또는 차원은 임베딩 모델에 따라 다른데 아래 모델은 768개의 값을 가진 벡터로 인코딩함
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')

# 텍스트 -> 텍스트 임베딩 변환
vector = model.encode('Best movie ever!')

# (768,)
print(vector.shape)
```