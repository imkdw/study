# 토크나이저 언어가 모델의 입력을 준비하는 방법
- 겉으로 봤을땐 생성 LLM은 입력 프롬프트를 받아서 응답을 생성함
- 하지만 실제로는 프롬프트를 언어 모델에 전달하기 전에 토크나이저에 통과시켜서 더 작은 단위로 쪼개야함
- 모델이 텍스트를 처리하기 전에 토크나이저가 텍스트를 단어나 부분단어로 나는데 이 과정은 토큰화 방법과 훈련 방식에 따라서 다름

<br>

# LLM 다운로드 / 실행
- 아래 내용처럼 모델이 직접 텍스트 프롬프트를 입력받지 않고 토크나이저가 입력 프롬프트를 처리해서 모델에게 필요한 정보를 input_ids에 저장
- 해당 내용에는 일련의 정수가 들어있고 이는 특정 토큰에 대한 고유한 ID를 뜻함
- 이는 테이블에 대한 참조값이며 이 테이블에는 토크나이저가 인식할 수 있는 모든 토큰이 담겨져있음
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-3-mini-4k-instruct",
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)
tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

prompt = "write an email apologizing to Sarah for the gragic gardening mishap. Exaplain how it happended.<|assistant|>"

input_ids = tokenizer(prompt, return_tensors="pt").input_ids.to("cuda")

"""
tensor([[ 2436,   385,  4876, 27746,  5281,   304, 19235,   363,   278,   330,
          1431,   293, 16423,   292,   286,   728,   481, 29889,  1222,   481,
          7420,   920,   372,  2250,  2760, 29889, 32001]], device='cuda:0')
"""
print(input_ids)

generation_output = model.generate(
    input_ids=input_ids,
    max_new_tokens=20
)

"""
write an email apologizing to Sarah for the gragic gardening mishap. Exaplain how it happended.<|assistant|> 

실제 생성한 토큰 : Subject: Sincere Apologies for the Gardening Mishap Dear Sarah
"""
print(tokenizer.decode(generation_output[0]))
```

<br>

### 토큰 분해하기
- 일부 토큰은 완전한 단어이며 일부 토큰은 부분단어임
- 구두점 또한 하나의 토큰임
```python
"""
write an email apolog izing to Sarah for the g rag ic garden ing m ish ap . Ex ap lain how it happ ended . <|assistant|> 
"""
for id in input_ids[0]:
  print(tokenizer.decode(id), end=" ")
```

<br>

# 토크나이저가 텍스트를 분할하는 방법
- 