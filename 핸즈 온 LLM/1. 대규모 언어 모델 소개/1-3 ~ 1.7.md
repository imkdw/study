# 대규모 언어 모델의 정의

- 최근 AI의 역사를 보면 디코더 기반의 생성 모델을 대규모 언어 모델이라고 부름
- 대규모 언어 모델이란 용어의 정의는 새로운 모델이 출시됨에 따라서 진화함

<br>

# 대규모 언어 모델의 훈련 패러다임

- 전통적인 ML은 분류와 같은 특정 작업을 위해서 모델을 훈련함
- 데이터(주로 구조적인 데이터) -> 훈련 -> 모델(훈련 후) 과정으로 표현됨
- 이와 달리 LLM을 만드는 것은 일반적으로 적어도 두 단계로 구성됨

<br>

# LLM을 만드는 과정

### 언어 모델링

- 첫번째는 `사전 훈련`이라고 부르고 대부분의 계산과 훈련 시간소요됨
- 인터넷에서 수집한 대규모 텍스트 말뭉치에서 LLM을 훈련시켜서 모델이 문법, 맥락, 언어 패턴을 학습할 수 있음
- 이 훈련 단계는 다음 언어를 예측하는 것 외에 아직 특정 작업이나 앱에 맞춰져 있지 않음
- 이런 모델을 `파운데이션 모델` 또는 `베이스 모델`이라고 부르고 일반적으로 명령을 따르지 못함

<br>

### 미세 튜닝

- `미세 튜닝(Fine Tuning)`, `사후 훈련(Post-training)`이라고 부름
- 이전에 훈련된 모델을 구체적인 작업에 맞춰서 추가로 훈련함
- 베이스 모델을 미세튜닝해서분류 작업을 수행하거나 명령을 따르게 할 수 있음

<br>

# LLM을 활용한 앱이 유용한 이유

- LLM은 특성상 광범위한 작업에 잘 맞음. 텍스트 생성, 프롬프트 덕분에 상상력이 유일한 제약인 것처럼 보임
- 고객이 남긴 리뷰가 긍정적인지 부정적인지 식별
- 이슈 티켓에서 자주 발생하는 주체를 찾는 시스템 개발
- 관련 문서 검색과 조사를 위한 시스템 개발
- 도구와 문서 같은 외부 자원을 활용할 수 있는 LLM 챗봇 만들기
- 냉장고 안을 찍은 사진을 기반으로 요리 레시피를 작성하는 LLM 구축

<br>

# 책임 있는 LLM 개발과 사용

- LLM의 놀라운 능력을 살펼볼 때 사회적, 윤리적 의미를 염두에 두는게 좋음
- 편향성/공정성 : LLM은 대규모 데이터에서 학습되는데 이 때 편향과 공정성이 매우 중요함. 재현하고 잠재적으로 증폭시킬 수 있음
- 투명성/책임성 : 대화 상태가 사람인지 LLM인지 구분할 수 없는데 사람의 감독 없이 LLM이 사람을 상대하면 의도하지 않는 결과를 낼 수 있음
- 유해 콘텐츠 생성 : 항상 올바른 컨텐츠를 생성하지 않고 잘못된 텍스트를 진짜인 것처럼 출력할 수 있음
- 지적 재산권 : 훈련 데이터를 확인하지 않고서는 저작권이 있는 자료를 LLM에 사용했는지 알 수 없음
- 규제 : LLM을 포함한 파운데이션 모델의 개발과 배포를 규제하는 EU 인공지능법이 있을정도로 상업적 앱을 규제하기 시작함

<br>

# 자원이 부족해도 괜찮음

- 모델 학습을 위해선 GPU의 VRAM이 많이 필요하고 실제로 많을수록 좋음
- 하지만 적은 사양으로도 모델을 다룰 수 있고 Colab 등에서 무료로 GPU 사용이 가능함

<br>
