# 프롬프트의 잠재적 복잡성
- 이러한 복잡성은 모듈식 특징을 잘 보여주며 구성요소를 자유롭게 추가/제거해서 출력에 미치는 영향을 파악하는 것이 가능함

<br>

### 페르소나
- LLM이 수행할 역할을 기술함
- ex) 천체물리학에 대해 질문하고 싶다면 `당신은 천체물리학 전문가 입니다`라고 씀

<br>

### 지시
- 작업 그 자체, 가능한 한 구체적으로 나타냄
- 달리 해석될 여지를 남기지 않는게 중요함
- ex) `제공된 논문의 주요 결과를 요약해주세요`

<br>

### 문맥
- 문제나 작업의 맥락을 설명하는 추가 정보
- ex) `요약은 연구자들이 논문의 가장 중요한 정보를 신속하게 이해하는 데 도움이 될 수 있는 가장 중요한 요점을 추출해야 합니다`

<br>

### 형식
- LLM이 생성한 텓스트를 출력하는 데 사용할 형식을 지정해야함
- 이를 지정하지 않으면 LLM이 스스로 형식을 구성하기 때문에 자동화된 시스템에서 문제가 됨
- ex) `방법의 개요를 설명하는 요약본을 작성해주세요. 이를 따라서 주요 결과를 요약하는 간결한 단락으로 이어집니다`

<br>

### 청중
- 생성된 텍스트의 소비 대상, 생성된 출력의 수준도 기술함
- 교육이 목적이라면 나이대상도 기록하는게 좋음
- ex) `이 요약은 바쁜 리서처들이 LLM에 대한 신규 트렌드를 따라잡을 수 있도록 작성되야합니다`

<br>

### 어투
- LLM이 생성된 텍스트에서 사용할 말투
- 만약 상사에게 메일을 쓴다면 격식을 차린 어투가 필요할것임
- ex) `톤이 갈끔하고 전문가 다워야합니다`

<br>

# 문맥 내 학습 : 예시 제공
- LLM에게 우리가 달성ㅎ려는 것의 예시를 정확하게 제공할 수 있음
- 모델에베 올바른 예시를 제공하는 방법을 `문맥 내 학습`이라고 부름
- 대표적으로 `제로샷`, `원샷`, `퓨샷`이 존재함

<br>

### 제로샷
- 프롬프트에 아무런 예시도 사용하지 않음
```
지시 : 아래 텍스트가 긍정인지 부정인지 평가하세요
텍스트 : ...
```

<br>

### 원샷
- 프롬프트에 한 개의 예시가 포함됨
```
지시 : 아래 텍스트를 중립, 긍정, 부정으로 평가하세요

예시 : 음식이 괜찮은 것 같아요
답변 : 중립

텍스트 : ...
답변 ...
```

<br>

### 퓨샷
- 두 개 이상의 예시가 포함된 프롬프트
```
지시 : 아래 텍스트를 중립, 긍정, 부정으로 평가하세요

예시 : 음식이 괜찮은 것 같아요
답변 : 중립

예시 : 음식이 맛있어요!
답변 : 긍정

예시 : 음식이 맛없어요
답변 : 부정

텍스트 : ...
답변 ...
```

<br>

# 프롬프트 체인 : 문제 쪼개기
- 문제를 프롬프트 안에서 분할하는 대신 여러 프롬프트로 분해도 가능함
- 모델을 여러번 호출해야 하지만 각각의 호출에 매개변수를 다르게 지정할 수 있는 것이 주요한 장점임

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline

model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-3-mini-4k-instruct",
    device_map="cpu",
    torch_dtype="auto",
    trust_remote_code=True
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    return_full_text=False,
    max_new_tokens=500,
    do_sample=False
)

messages = [
    {
        "role": "user",
        "content": "Create a funny joke about chickens"
    }
]

# LLM 챗봇의 제품의 슬로건과 이름 만들기
product_prompt = [
    {"role": "user", "content": "Create a name and slogan for a chatbot that leverages LLMs."}
]
outputs = pipe(product_prompt)
product_description = outputs[0]["generated_text"]

"""
Name: ChatSage
Slogan: "Your AI Companion for Smart Conversations"
"""
print(product_description)


# 생성된 상품 정보 홍보물? 만들기
sales_prompt = [
    {"role": "user", "content": f"Generate a very short sales pitch for the following product: '{product_description}'"}
]
outputs = pipe(sales_prompt)
sales_pitch = outputs[0]["generated_text"]

"""
Introducing ChatSage, your AI Companion for Smart Conversations.
With ChatSage, you'll have a personalized and intelligent assistant at your fingertips,
ready to engage in meaningful dialogue, provide helpful information, and enhance your daily interactions.
Experience the future of communication with ChatSage – your smart conversation partner.
"""
print(sales_pitch)
```

<br>

### 활용사례
- 응답 유효성 검사 : 이전에 생성한 출력을 재확힌하도록 LLM에게 요청
- 병렬 프롬프트 : 여러 개의 프롬프트를 병렬로 만들고 최종 단계에서 병합함
  - 예를 들면 복수의 LLM에게 여러개의 레시피를 병렬로 생성하게 요청하고 그 다음 이 결과를 합쳐서 쇼핑 목록을 만들도록함
- 이야기 작성 : LLM을 활용하고 문제를 여러 요소를 나누느 방식을 사용해서 책이나 이야기를 작성
  - 먼저 요약을 작성하고 캐릭터를 개발, 핵심 장면 생성, 그다음 대화를 만드는 단계로 넘어감