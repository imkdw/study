# 대조 학습이란?
- 대조 학습은 벡터 공간에서 비슷한 문서가 가까이 놓이고 비슷하지 않은 문서는 멀리 떨어지도록 임베딩 모델을 훈련하는 것이 목적임
- 문서 간 유사/비유사성을 학습하고, 모델링하는 가장 좋은 방법은 비슷한 샘플 쌍과 비슷하지 않은 샘플 쌍을 모델에게 제공하는 것임
- 대조학습은 설명의 본질을 생각하는 것이라고 할 수 있음. 이를 `대조적 설명`이라고 부름
  - ex) 정확한 질문이지만 질문의 구체적인 의도를 만족하지 못함, 원하는건 왜 범죄를 저질럿냐임
    - 기자 -> 도둑 : 왜 은행을 털었나요?
    - 도둑 -> 기자 : 돈이 있어서요
  - ex) 구체적인 의도를 만족하기 위한 질문 예시
    - 기자 -> 도둑 : 왜 법을 지키지 않고 은행을 털었나요

<br>

### 질문을 이해하는 방식의 중요성
- 이는 대조 학습을 통해 임베딩을 어떻게 학습하는지에도 적용됨
- 모델에게는 비슷한 문서 쌍과 비슷하지 않은 문서 쌍을 주고 학습하는데 여기서 `그 이유가 무엇인가`를 학습하기 시작함
- 대조 학습을 통해서 텍스트 임베딩 모델을 만들수있는 방법은 많지만 가장 잘 알려진 기법이자 프레임워크는 `sentence-transformers`임